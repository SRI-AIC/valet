from typing import Dict, Any, List

import plac
import math
import re
import logging
import sys

_logger = logging.getLogger(__name__)


"""
Using the Co-clustering class:

This class is used to read in and make available the data generated by 
running the JMiner co-clustering code (referred to as the DTI Pipeline in the 
JMiner lingo). When constructing the class, provide the 'input_directory' 
parameter with a path to the coclustering files where artifacts such as 
xyCooc.tsv live. 
If your documents are tagged with their target, provide the 
target label to the 'target_label' parameter and the non-target label to the 
'non_target_label' parameter. This will count the number of target vs 
non-target documents in each document cluster (% purity) as well as find what 
terms are most commonly found in target documents. This does not affect the 
coclustering (it is still unsupervised) as it does not treat the document 
names any differently. For an example dataset that exposes this feature 
contact daragh.hartnett@sri.com 

Once the co-clustering data has been ingested (see the read_XXX() methods in 
Section A for details), there are 2 ways to access the ingested data in this 
class. 
The first is to make use of the query methods that abstract the 
underlying data structures and instead provide useful functionality. An 
example of this is get_term_cluster_siblings_sorted_by_divergence(self, 
term_index, limit=20). This method will return a list of terms, sorted by 
divergence from the provided term, that occur in the same term cluster. These 
methods are gathered together in Section B. 
The second is to get a handle on 
the raw data structures such as the xy_cooc, y_labels and such. For this see 
the accessor methods at the end of the class (get_xy_xooc() and get_y_labels(
) for example) in Section C. 

Co-clustering Terminology:
TODO: currently low priority since most of us know what an x, y, a, b etc are.
"""


# Coclustering is currently an alias for this class, defined after this class.
class DoubleCoclustering(object):

    def __init__(self, input_directory, adj_input_directory=None,
                 target_label=None, non_target_label=None):
        """
        Parameters
        ----------
        input_directory - path to the by-document coclustering files where artifacts such as xyCooc.tsv live
        adj_input_directory - (optional) path to the by-adjacency coclustering files where artifacts such as
                                    xyCooc.tsv live.
        target_label - (optional) the string label in the document name that identifies it as a target
        non_target_label - (optional) the string label in the document name that identifies it as a non target
        """

        self.input_directory = input_directory  # used by get_document_text
        # self.adj_input_directory = adj_input_directory
        # self.target_label = target_label
        # self.non_target_label = non_target_label

        self.bydoc = SingleCoclustering(input_directory,
            target_label=target_label, non_target_label=non_target_label)
        if adj_input_directory is not None:
            self.byadj = SingleCoclustering(adj_input_directory,
                target_label=None, non_target_label=None)
        else:
            self.byadj = None

        # Note: After construction you should call the data load methods:
        #   read_cooc_input_data()
        #   read_cocl_output_data()
        #   read_cocl_association_data()
        # to populate the data structures. This is no
        # longer done automatically to allow a skeleton data load
        # for specific applications.


    def read_cooc_input_data(self):
        """
        Calls a read function for the co-occurrence data. This data is used
        to drive the co-clustering algorithm. Each of the methods below reads
        in a particular file. For example, read_xy_cooc reads and ingests the
        xyCooc.tsv file.

        Each structure that is populated by the read method is initialized
        and explained before the call to the read method.
        """

        self.bydoc.read_cooc_input_data()

        if self.byadj is not None:
            # Historically this just reads part of the adjacency data.
            self.byadj.x_labels = self.byadj.read_x_labels()
            # self.byadj.x_to_x_divergence = self.byadj.read_xx_assoc()


    def read_cocl_output_data(self):
        """
        Calls a read function for the co-clustering output data. This data is
        produced by the co-clustering algorithm. The data structures that are
        populated by these methods can also be populated by setter methods
        directly. Each structure that is populated by the read method is
        explained before the call to the read method.
        """

        self.bydoc.read_cocl_output_data()

        if self.byadj is not None:
            # Historically this just reads part of the adjacency data.
            # Read the by adjacency co-clustering output data.
            # - self.term_cluster_to_terms_adj_map is a dictionary
            #   to a list of terms for each of the term clusters (ax_map)
            # - self.term_to_term_cluster_adj_map is a dictionary
            #   from term index to term cluster index (xa_map)
            self.byadj.x_cluster_to_x_map, self.byadj.x_to_x_cluster_map = \
                self.byadj.read_xa_map()


    def read_cocl_association_data(self):
        """
        Calls a read function for the post co-clustering generated files.
        These are additional data structures that are not generated during
        the standard co-clustering algorithm.
        """

        self.bydoc.read_cocl_association_data()
        
        if self.byadj is not None:
            # Historically this just reads part of the adjacency data.
            # Read the by adjacency co-clustering association output data.
            # - self.term_to_term_adj_divergence is a dictionary
            #   from a tuple of term indices to their relative
            #   divergence, or distance, from each other.
            self.byadj.x_to_x_divergence = self.byadj.read_xx_assoc()


    # For backward compatibility. Now primarily defined at module level.
    # Suggest changing callers if feasible.
    def calculate_entropy(self, values):
        return calculate_entropy(values)
    def calculate_generalized_mean(self, divergences, exponent):
        return calculate_generalized_mean(divergences, exponent)
    def calculate_pmi(self, total, row_sum, col_sum, count):
        return calculate_pmi(total, row_sum, col_sum, count)


    # The read_ methods all seem to return values rather than setting fields.
    # TODO? None of these methods seem to be needed at the DoubleCoclustering 
    # level anymore, hence hide_.

    """
    Section A. 
    The methods below read the Co-Clustering data into 
    structures that allow them to be queried in interesing ways (see Section 
    B). They also populate direct access structures for clients that want the 
    raw data (see Section C)
    """

    
    def hide_read_xy_dims(self):
        """
        Read the xyDims.tsv file. This contains the number of terms and
        the number of documents in the co-occurrence data.
        This data is added to 2 module member variables:
            self.term_count
            self.document_count
        """

        return self.bydoc.read_xy_dims()


    def hide_read_x_labels(self):
        """
        Read the xLabels.tsv file. This contains the terms in the corpus
        (x's) used as input to co-clustering. This is a 0 based numbering
        system. For example, the term, say 'dog' on line 1 will have a
        term_index of 0. This term_index is used to index structures such as
        the xyCooc.tsv.
        """

        return self.bydoc.read_x_labels()


    def hide_read_y_labels(self):
        """
        Read the yLabels.tsv file. This contains the names of the documents
        (y's) used in the co-clustering run. This is a 0 based numbering
        system. For example, the document, say doc1.txt on line 1 will have a
        document_index of 0. This document_index is used to index structures
        such as the xyCooc.tsv.
        """

        return self.bydoc.read_y_labels()


    def hide_read_xy_cooc(self):
        """
        Reads the xyCooc.tsv file. This contains the sparse matrix data
        representing the occurrences, or frequency, between terms (x's) and
        documents (y's). An example entry in this file is 0\t3\t88. This
        translates to term_index '0' occurs in document_index '3' a total of
        88 times.
        """

        return self.bydoc.read_xy_cooc()


    def hide_read_ab_dims(self):
        """
        Read the abDims.tsv file. This contains the number of term clusters
        and the number of document clusters. This data is added to
        2 module member variables:
            self.term_cluster_count
            self.document_cluster_count
        """

        return self.bydoc.read_ab_dims()


    def hide_read_ab_cooc(self):
        """
        Reads the abCooc.tsv file. This contains the sparse matrix data
        representing the occurrences, or frequency, between term_clusters (
        a's) and document_clusters (b's). An example entry in this file is
        0\t3\t88. This translates to the terms in term_cluster_index '0'
        occur in the documents in document_cluster_index '3' a total of 88
        times.
        """

        return self.bydoc.read_ab_cooc()


    def hide_read_xa_map(self):
        """
        Reads the xaMap.tsv file. This tells us which terms (x's) belong to
        which term clusters (a's). This is a zero based system. For example,
        an entry in this file looks like this: '3'. Lets say this is on line
        7 of the file, since it is a zero based counting system, this tells
        us the term_index '6' belongs to term cluster '3'.
        """

        return self.bydoc.read_xa_map()


    def hide_read_yb_map(self):
        """
        Read the ybMap.tsv file. This tells us which documents (y's) belong
        to which document clusters (b's). This is a zero based system. For
        example, an entry in this file looks like this: '3'. Lets say this is
        on line 7 of the file, since it is a zero based counting system,
        this tells us the term_index '6' belongs to term cluster '3'.
        """

        return self.bydoc.read_yb_map()


    def hide_read_xb_cooc(self):
        """
        Reads the xbCooc.tsv file. This contains the sparse matrix data
        representing the occurrences, or frequency, between terms (x's) and
        document clusters (b's). An example entry in this file is 0\t3\t88.
        This translates to term_index '0' occurs in document_cluster '3' a
        total of 88 times.
        """

        return self.bydoc.read_xb_cooc()


    def hide_read_xy_assoc(self):
        """
        Reads the xyAssoc.tsv file. This contains the PMI score between the
        terms (x's) ands the documents (y's). An example entry in this file
        is 0\t3\t0.224. This translates to term_index '0' and document '3'
        have a pointwise mutual information measure of 0.224.

        Note: some of the PMI values are negative - Positive PMI means that
        that the term is MORE likely to occur in this document than it is
        overall, negative should mean it's LESS likely to occur this document
        than it is overall, and zero means that it's AS likely to occur in
        this document as any other.
        """

        return self.bydoc.read_xy_assoc()


    def hide_read_xb_assoc(self):
        """
        Reads the xbAssoc.tsv file. This contains the PMI score between the
        terms (x's) ands the document clusters (b's). An example entry in
        this file is 0\t3\t0.224. This translates to term_index '0' and
        document_cluster '3' have a pointwise mutual information measure of
        0.224.

        Note: some of the PMI values are negative - Positive PMI means that
        that the term is MORE likely to occur in this document cluster than
        it is overall, negative should mean it's LESS likely to occur this
        doc cluster than it is overall, and zero means that it's AS likely to
        occur in this doc cluster as any other.
        """

        return self.bydoc.read_xy_assoc()


    def hide_read_xx_assoc(self):
        """
        Reads the xxAssoc.tsv file. This contains the divergence score
        between the terms (x's). An example entry in this file is
        0\t3\t0.224. This translates to term_index '0' and term_index '3'
        have a divergence measure of 0.224. Divergence is like distance,
        the smaller the number, the closer those two terms should be
        considered in meaning or context.
        """

        return self.bydoc.read_xx_assoc()


    def hide_read_bb_assoc(self):
        """
        Reads the bbAssoc.tsv file. This contains the divergence score
        between the document clusters (b's). An example entry in this file is
        0\t3\t0.224. This translates to doc_cluster '0' and doc_cluster '3'
        have a divergence measure of 0.224. Divergence is like distance,
        the smaller the number, the closer those two document clusters should
        be considered in meaning or context.
        """

        return self.bydoc.read_bb_assoc()


    def hide_read_x_margins(self):
        """
        Read the xMargs.tsv file. This holds the row totals that correspond
        to how many times each term (x) appears in the corpus. An example of
        this in the file is '849' on first line. This means that the term
        with index '0' occurred 849 times in the entire set of documents.
        """

        return self.bydoc.read_x_margins()


    def hide_read_b_margins(self):
        """
        Read the bMargs.tsv file. This holds the column totals that
        correspond to how many times each of the terms (x's) occur in each
        document cluster (b). An example of this in the file is '6265' on
        first line. This means that the document_cluster with index '0' had a
        total term occurrence of 6265.
        """

        return self.bydoc.read_x_margins()


    """
    Section B.
    The methods below give access to the massaged data in the 
    CoClustering structure. For instance they offer access to sorted lists of 
    associations between various structures such as the list of terms most 
    aligned with a specific document cluster for instance. For direct to the 
    underlying structures, see Section C
    """


    # This goes a bit beyond the usual coclustering methods.
    def get_document_text(self, document_label):
        """
        Get the text of the document (y) with the specified label.

        Parameters
        ----------
        document_label : string
            The label of the document that we want the text for.

        Returns
        -------
        The text contents of the specified document. The data is returned
        as a single string, all carriage returns are replaced by spaces.
        """

        # The convention of a docs/ directory (usually a symlink)
        # under the TERM_BY_{DOC,ADJ}_COCL_OLD_FORMAT directory is now 
        # used in a few places, originally by the cocl-render.html file.
        document_path = "%s/docs/%s" % (self.input_directory, document_label)
        data = ""
        with open(document_path, 'r') as file:
            data = file.read().replace('\n', ' ')
        return data


    # This goes WELL beyond the usual coclustering methods.
    # TODO? Perhaps ought to go elsewhere.
    def generate_marked_up_document(self, document_label, mwus_only=False, minimum_pmi=0.0):
        """
        Given a document label, retrieve the documents text content and add
        html markup to the terms that have at least the specified minimum_pmi
        with the specified document. This method is handy for quickly
        rendering the document content along with the key terms in Jupyter
        Notebook. The markup is currently configured to highlight the chosen
        terms in bold along with their pmi with the document in braces. For
        example <b>apple tree</b>(0.341)

        Parameters
        ----------
        document_label : string
            label of the document that we want the markedup content for
        mwus_only : boolean
            If True, only mark up the Multi Word Units ('apple tree' for example, vs 'tree' and 'apple')
        minimum_pmi : float
            the minimum pmi measure that a term must have with a document to be included in the markup

        Returns
        -------
        Document content that corresponds to the specified document label
        with terms that qualify for inclusion highlighed in bold with their
        pmi with the document in braces.
        """

        # This method is one of only a few places where the DoubleCoclustering 
        # methods with term/document-oriented naming are still used,
        # other than in tests.
        # TODO? We could replace them with calls directly to the
        # SingleCoclustering methods, or we could add a subclass
        # ByDocCoclustering.

        document_index = self.get_document_index_from_label(document_label=document_label)
        # Get the text
        document_text = self.get_document_text(document_label=document_label).lower()
        # Find out its assigned document cluster id
        document_cluster_id = self.get_document_cluster_id_for_document(document_label=document_label)
        # Get the terms that occur in the document cluster
        terms_in_document = self.get_terms_in_document(document_index)

        for term_index in terms_in_document:
            term = self.get_x_labels()[term_index]
            if mwus_only:
                if " " not in term:
                    continue
            if len(term) > 2:
                pmi_value = self.get_pmi_term_to_document_cluster(term_index=term_index, doc_cluster=document_cluster_id)
                if pmi_value >= minimum_pmi:
                    pmi = str(round(pmi_value, 4))
                    document_text = re.sub(r'\b%s\b' % term, '<b>%s</b>(%s)' % (term, pmi), document_text)

        return document_text


    def get_term_cluster_count(self):
        """
        Get the number of term clusters in the co-clustering data

        Returns
        -------
        The number of term clusters in the co-clustering data
        """
        return self.bydoc.get_x_cluster_count()


    def get_document_cluster_count(self):
        """
        Get the number of document clusters in the co-clustering data

        Returns
        -------
        The number of document clusters in the co-clustering data
        """
        return self.bydoc.get_y_cluster_count()


    def get_document_count_in_cluster(self, cluster_index):
        """
        Get the number of documents that occur in the specified document_cluster_index

        Parameters
        ----------
        cluster_index : int
            The index of the document_cluster that we want to get the document count for

        Returns
        -------
        the number of documents that occur in the specified document_cluster_index
        """
        return self.bydoc.get_y_count_in_cluster(cluster_index)


    def get_document_labels_in_document_cluster(self, document_cluster_index):
        """
        Get the list of document labels (what appears in the yLabels.tsv file)
        that belong to the specified document_cluster_index

        Parameters
        ----------
        document_cluster_index : int
            The index of the document_cluster that we want to get the assigned document labels for

        Returns
        -------
        The list of document labels that belong to the specified document_cluster_index
        """
        
        return self.bydoc.get_y_labels_in_y_cluster(document_cluster_index)

    
    def get_document_cluster_id_for_document(self, document_label):
        """
        Get the assigned document_cluster_id for the provided document_label.
        This information is stored in the ybMap.tsv file.

        Parameters
        ----------
        document_label : string
            The label of the document (y) that we want to know the assigned document_cluster_id for

        Returns
        -------
        Assigned document_cluster_id for the provided document_label
        """

        return self.bydoc.get_y_cluster_for_y_label(document_label)


    def get_document_cluster_target_purity(self, document_cluster_index):
        """
        Get the % purity of the specified document_cluster_index. Purity is
        defined as the ration of target to non_target documents in the
        document cluster. Note, this feature is only available when the
        target_label and non_target_label is provided during construction.
        See the 'Using the Co-clustering class' notes at the top of this
        class for further details

        Parameters
        ----------
        document_cluster_index : int
            The index of the document_cluster that we want to get the % purity for

        Returns
        -------
        The % purity of the specified document_cluster_index
        """

        return self.bydoc.get_y_cluster_target_purity(document_cluster_index)


    def get_document_cluster_non_target_purity(self, document_cluster_index):
        """
        Get the % non_purity of the specified document_cluster_index.
        Non-purity is defined as the ration of non-target to target documents
        in the document cluster. Note, this feature is only available when
        the target_label and non_target_label is provided during
        construction. See the 'Using the Co-clustering class' notes at the
        top of this class for further details

        Parameters
        ----------
        document_cluster_index : int
            The index of the document_cluster that we want to get the % non-purity for

        Returns
        -------
        The % non-purity of the specified document_cluster_index
        """

        return self.bydoc.get_y_cluster_non_target_purity(document_cluster_index)


    # Called from test code. 
    def calculate_document_cluster_variance(self, document_cluster_index):
        """
        For a given document cluster, calculate its variance. This is a
        measure of how dissimilar its documents are from each other. A
        variance of 0.0 means that the document cluster contains 100%
        duplicate (or a total of 1) documents. The higher the variance,
        the more dissimilar the documents are from each other. This is used
        to detect boiler plate documents. See
        https://www150.statcan.gc.ca/n1/edu/power-pouvoir/ch12/5214891-eng.htm#:~: text=We%20know%20that%20variance%20is,and%20the%20variance%20is%200.667.
        for further details.
        """

        return self.bydoc.calculate_y_cluster_variance(document_cluster_index)


    def get_document_cluster_entropy(self, document_cluster_index):
        """
        Get the entropy of the specified document_cluster_index

        Parameters
        ----------
        document_cluster_index : int
            The index of the document_cluster that we want the entropy for

        Returns
        -------
        The entropy of the specified document_cluster_index
        """

        return self.bydoc.get_y_cluster_entropy(document_cluster_index)



    def get_terms_in_doc_cluster_ordered_by_freq(self, document_cluster_index, mwus_only=False):
        """
        Get the terms and their frequency in the specified document_cluster_index

        Parameters
        ----------
        document_cluster_index : int
            The index of the document_cluster that we want the terms for
        mwus_only : bool
            If True, only return terms that are multi word units
             ('apple tree' for example), if false, return all terms

        Returns
        -------
        Sorted list of tuples of term_indices to their frequency in the
        specified document_cluster. Sorted from most frequent to least frequent

        """

        return self.bydoc.get_terms_in_doc_cluster_ordered_by_freq(
            document_cluster_index, mwus_only=mwus_only)


    def get_pmi_term_to_document_cluster(self, term_index, doc_cluster):
        """
        Get the Pointwise Mutual Information measure between the specified
        term_index and document_cluster_index
        Parameters
        ----------
        term_index : int
            index of the term we want the pmi measure for
        doc_cluster : int
            index of the document_cluster that we want the pmi measure for

        Returns
        -------
        The Pointwise Mutual Information measure between the
        specified term_index and document_cluster_index. If no value is
        available for the specified pair, None is returned.

        Note - some of the PMI values are negative - Positive PMI means that
        that the term is MORE likely to occur in this document cluster than
        it is overall, negative should mean it's LESS likely to occur this
        doc cluster than it is overall, and zero means that it's AS likely to
        occur in this doc cluster as any other.
        """

        return self.bydoc.get_pmi_x_to_y_cluster(term_index, doc_cluster)


    def generate_pmi_term_to_document_cluster(self, term_index, doc_cluster):
        """
        Calculate the Pointwise Mutual Information measure between the
        specified term_index and document_cluster_index. Note: some of the
        PMI values are negative - Positive PMI means that that the term is
        MORE likely to occur in this document cluster than it is overall,
        negative should mean it's LESS likely to occur this doc cluster than
        it is overall, and zero means that it's AS likely to occur in this
        doc cluster as any other.

        Parameters
        ----------
        term_index : int
            index of the term we want the pmi measure for
        doc_cluster : int
            index of the document_cluster that we want the pmi measure for

        Returns
        -------
        The Pointwise Mutual Information measure between the specified term_index and document_cluster_index
        """

        return self.bydoc.generate_pmi_x_to_y_cluster(term_index, doc_cluster)


    def get_pmi_term_to_document(self, term_index, doc_index):
        """
        Get the Pointwise Mutual Information measure between the specified
        term_index and doc_index

        Parameters
        ----------
        term_index : int
            index of the term we want the pmi measure for
        doc_index : int
            index of the document that we want the pmi measure for

        Returns
        -------
        The Pointwise Mutual Information measure between the
        specified term_index and document_cluster_index. If no value is
        available for the specified pair, None is returned.

        Note - some of the PMI values are negative - Positive PMI means that
        that the term is MORE likely to occur in this document cluster than
        it is overall, negative should mean it's LESS likely to occur this
        doc cluster than it is overall, and zero means that it's AS likely to
        occur in this doc cluster as any other.
        """
        return self.bydoc.get_pmi_x_to_y(term_index, doc_index)


    #
    # What's the story on this target concept?
    # Is it potentially applicable at all to adjacency (or even entity)
    # based clustering, or is it inherent to document based?
    # I think it IS at least potentially applicable.
    # Instead of being 
    #     the number of target and non-target documents that the specified
    #     terms occur IN
    # the more general concept is 
    #     the number of target and non-target contexts that the specified
    #     terms (or more generally x cats) (co-)occur WITH
    # However, in practice it's unlikely to happen.
    #


    def get_target_document_count_for_terms(self, terms):
        """
        Get the number of target and non-target documents that the specified
        terms occur in. Note, this feature is only available when the
        target_label and non_target_label is provided during construction.
        See the 'Using the Co-clustering class' notes at the top of this
        class for further details.

        Parameters
        ----------
        terms : list of string
            list of terms that we want to get a target and non-target document count for

        Returns
        -------
        The number of target documents the terms occur in and
        the number of non-target documents the terms occur in. Documents are
        not double counted, if 2 terms occur in the same document it is
        included in the count only once.
        """

        return self.bydoc.get_target_y_count_for_xs(terms)


    def get_term_index_from_term(self, term):
        """
        Convenience function that returns the term_index for the provided term

        Parameters
        ----------
        term : string
            The term string that we want to get the term_index for

        Returns
        -------
        The term_index for the provided term
        """

        return self.bydoc.get_x_index_from_x_label(term)


    def get_term_to_term_divergence(self, term1, term2, adjacency=False):
        """
        Get the divergence measure (distance) between the two specified term indices

        Parameters
        ----------
        term1 : int
            index of the first term to get the divergence measure for
        term2 : int
            index of the second term to get the divergence measure for
        adjacency : boolean
            if true, use the by-adjacency co-clustering output, false, use the by-document co-clustering output

        Returns
        -------
        The divergence measure (distance) between the two
        specified term indices. The divergence map may have been pruned,
        leaving open the possibility that no divergence is recorded for a
        given pair of terms.  In that case, return a very high divergence.
        """

        if not adjacency:
            return self.bydoc.get_x_to_x_divergence(term1, term2)
        else:
            if self.byadj is None:
                give_adjacency_data_warning("get_term_to_term_divergence")
                return None
            return self.byadj.get_x_to_x_divergence(term1, term2)


    def get_doc_cluster_to_doc_cluster_divergence(self, doc_cluster_1, doc_cluster_2):
        """
        Get the divergence measure (distance) between the two specified document cluster indices

        Parameters
        ----------
        doc_cluster_1 : int
            index of the first document cluster to get the divergence measure for
        doc_cluster_2 : int
            index of the second document cluster to get the divergence measure for

        Returns
        -------
        The divergence measure (distance) between the two specified document cluster indices
        """

        return self.bydoc.get_y_cluster_to_y_cluster_divergence(doc_cluster_1, doc_cluster_2)


    def get_term_cluster_siblings_sorted_by_divergence(self, term_index, limit=20, adjacency=False):
        """
        Get a list of term_indices, sorted by divergence, from closest
        to furthest, in the same term cluster as the specified term_index.

        Parameters
        ----------
        term_index : int
            the term_index to get the sorted list of term_cluster siblings for
        limit : int
            the number of term siblings that should be returned. The default value here is 20.
        adjacency : boolean
            if true, use the by-adjacency co-clustering output, false, use the by-document co-clustering output

        Returns
        -------
        List of term_indices, sorted by divergence, from closest to furthest,
        in the same term cluster as the specified term_index.
        """

        if not adjacency:
            return self.bydoc.get_x_cluster_siblings_sorted_by_divergence(term_index, limit=limit)
        else:
            if self.byadj is None:
                give_adjacency_data_warning("get_term_siblings_sorted_by_divergence")
                return None
            return self.byadj.get_x_cluster_siblings_sorted_by_divergence(term_index, limit)


    def get_document_clusters_sorted_by_divergence(self, document_cluster_index):
        """
        Get a list of document_cluster_indices, sorted by divergence,
        from closest to furthest from the specified document cluster

        Parameters
        ----------
        document_cluster_index : int
            the document cluster to compare to the other document clusters

        Returns
        -------
        List of document cluster indices, sorted by divergence, from closest
        to furthest from the specified document cluster
        """

        return self.bydoc.get_y_clusters_sorted_by_divergence(document_cluster_index)


    def rank_document_clusters_against_multiple_doc_cluster(self, document_clusters, exponent=0.1):
        """
        Given a group of document clusters, rank the other document clusters
        against them from closest to farthest. This method uses the
        generalized mean algorithm
        https://en.wikipedia.org/wiki/Generalized_mean which was suggested by
        John Niekrasz and Bob Sasseen. This mechanism allows us to measure
        distance between each document cluster and the provided group as a
        whole.

        Parameters
        ----------
        document_clusters : list of ints
            the indices of the document clusters we want to compare to all other document clusters
        exponent : float
            sensitivity of the generalized mean calculation

        Returns
        -------
            list of lists of document cluster indices to their generalized
            mean distance to the group of document
            clusters provided. Sorted from nearest to farthest
        """
        
        return self.bydoc.rank_y_clusters_against_multiple_y_cluster(document_clusters, exponent=exponent)


    def rank_terms_nearest_to_select_terms(self, term_indices, exponent=0.1, adjacency=False, limit=200):
        """
        Given a group of terms, rank the other terms against them from
        closest to farthest. This method uses the generalized mean algorithm
        https://en.wikipedia.org/wiki/Generalized_mean which was suggested by
        John Niekrasz and Bob Sasseen. This mechanism allows us to measure
        distance between each term and the provided group of terms as a whole.

        Parameters
        ----------
        term_indices : list of ints
            the indices of terms that we want to compare to all other terms as a group
        exponent : float
            sensitivity of the generalized mean calculation
        adjacency : boolean
            if true, use the by-adjacency co-clustering output, false, use the by-document co-clustering output
        limit : int
            maximum number of terms to return


        Returns
        -------
            list of lists of term indices to their generalized mean distance
            to the group of terms provided. Sorted from
            nearest to farthest
        """

        if not adjacency:
            return self.bydoc.rank_xs_nearest_to_select_xs(term_indices, exponent=exponent, limit=limit)
        else:
            if self.byadj is None:
                give_adjacency_data_warning("rank_terms_nearest_to_select_terms")
                return None
            return self.byadj.rank_xs_nearest_to_select_xs(term_indices, exponent=exponent, limit=limit)


    def rank_document_clusters_nearest_to_select_terms(self, term_indices):
        """
        Rank the document clusters by PMI with the provided terms. This
        feature allows the caller to identify document clusters that have a
        high correlation with the supplied terms when considered together.

        Algorithm being applied (compliments of Bob Sasseen):
                scores = array(# of Bs)
                for all Bs
                  scores[B] = 0
                  sumwts = 0
                  for all Xs in your term set
                     wt = XBCooc(X,B) / XYTotal
                     scores[B] += xbPmi(X,B) * wt
                     sumwts += wt
                  // end for X
                  scores[B] /= sumwts
                // end for B

        Parameters
        ----------
        term_indices : list of int
            list of term_indices that we want to measure against document clusters.

        Returns
        -------
        List of tuples from document cluster index to their pmi measure against the supplied term_indices
        """

        return self.bydoc.rank_y_clusters_nearest_to_select_xs(term_indices)


    def rank_terms_nearest_to_select_document_clusters(self, document_cluster_indices, limit=50):
        """
        Rank the terms by PMI with the provided document clusters. This
        feature allows the caller to identify terms that have a high
        correlation with the supplied document clusters when considered
        together.

        Algorithm being applied (compliments of Bob Sasseen):
                scores = array(# of X)
                for all Xs
                  scores[X] = 0
                  sumwts = 0
                  for all Bs in your document cluster set
                     wt = XBCooc(X,B) / XYTotal
                     scores[X] += xbPmi(X,B) * wt
                     sumwts += wt
                  // end for B
                  scores[X] /= sumwts
                // end for X
        Parameters
        ----------
        document_cluster_indices : list of int
            list of document_cluster_indices that we want to measure against terms.

        Returns
        -------
        List of tuples from document cluster index to their pmi measure
        against the supplied term_indices
        """

        return self.bydoc.rank_xs_nearest_to_select_y_clusters(document_cluster_indices, limit=limit)


    def rank_documents_nearest_to_select_terms(self, term_indices, limit=100):
        return self.bydoc.rank_ys_nearest_to_select_xs(term_indices, limit=limit)


    # Probably no longer necessary but we will leave it here for now
    def choose_closest_entities(self, total_entities, comparison_entities, generalized_divergences):
        return self.bydoc.choose_closest_entities(total_entities, comparison_entities, generalized_divergences)


    def get_term_cluster_for_term_index(self, term_index, adjacency=False):
        """
        Get the term_cluster_index that the specified term_index is assigned to.

        Parameters
        ----------
        term_index : int
            term_index that we want the assigned term_cluster_index for
        adjacency : boolean
            if true, use the by-adjacency co-clustering output, false, use the by-document co-clustering output

        Returns
        -------
        The term_cluster_index that the specified term_index is assigned to
        """
        
        if not adjacency:
            return self.bydoc.get_x_cluster_for_x_index(term_index)
        else:
            if self.byadj is None:
                give_adjacency_data_warning("get_term_cluster_for_term_index")
                return None
            return self.byadj.get_x_cluster_for_x_index(term_index)


    def get_closest_terms_sorted_by_divergence(self, term_index, limit=20, adjacency=False):
        """
        Get tuples of term_indices to divergence with the specified
        term_index, sorted by closest first. Note this will compare the
        specified term to *all* terms, not only those that are in the same
        term_cluster (the term_cluster functionality is available in the
        get_term_cluster_siblings_sorted_by_divergence() method).

        Parameters
        ----------
        term_index : int
            the term_index that we want to get the closest terms for
        limit : int
            the number of term indices to return. Default is 20
        adjacency : boolean
            if true, use the by-adjacency co-clustering output, false, use the by-document co-clustering output

        Returns
        -------
        Tuples of term_indices to divergence with the specified term_index, 
        sorted by closest first. Term count
        returned is limited by the 'limit' parameter.
        """

        if not adjacency:
            return self.bydoc.get_closest_xs_sorted_by_divergence(term_index, limit=limit)
        else:
            if self.byadj is None:
                give_adjacency_data_warning("rank_terms_nearest_to_select_terms")
                return None
            return self.byadj.get_closest_xs_sorted_by_divergence(term_index, limit=limit)


    def get_document_cluster_counts_over_term_clusters(self, doc_cluster_index):
        """
        Get the co-occurrences between the specified document_cluster_index
        and the term clusters (column in the ab_cooc structure).

        Parameters
        ----------
        doc_cluster_index : int
            the index of the document_cluster that we want the term_cluster co-occurrences for

        Returns
        -------
        List of tuples from term_cluster_index to co-occurrences
        with the specified document_cluster_index
        """
        # TODO? Rationalize some of these names Daragh invented.
        return self.bydoc.get_y_cluster_counts_over_x_clusters(doc_cluster_index)


    def get_terms_in_document(self, document_index):
        """
        Get the list of term_indices that are present in (co-occur with)
        the specified document_index. This information comes from the yx_map

        Parameters
        ----------
        document_index : int
            index of the document that we want the co-occurring term indices for

        Returns
        -------
        The list of term_indices that are present in (co-occur with) the specified document_index
        """

        return self.bydoc.get_y_to_xs(document_index)


    def get_document_index_from_label(self, document_label):
        """
        Convenience method for getting the document_index that corresponds
        to the supplied document_label.

        Parameters
        ----------
        document_label : string
            the document_label of the document that we want the document_index for

        Returns
        -------
        The document_index that corresponds to the supplied document_label
        """

        return self.bydoc.get_y_index_from_label(document_label)


    # TODO? This is not a great name.
    def get_document_occurrences_in_document_cluster(self, term_index, document_cluster_index):
        """
        Given a term_index, find the number of documents it appears in,
        in the provided document_cluster_index. This is used to determine how
        common a term is in the documents assigned to a particular document
        cluster.

        Parameters
        ----------
        term_index : int
            index of the term to get document count for
        document_cluster_index : int
            index of the document cluster that we want a document presence count for

        Returns
        -------
        the number of documents in the specified document cluster that a term appears in.
        """

        return self.bydoc.get_y_occurrences_in_y_cluster(term_index, document_cluster_index)


    """
    Section C.
    The methods below give direct access to the Co-Clustering structures such as the xy_cooc, ab_map etc. 
    """


    def get_term_count(self):
        """
        Get the number of terms in the co-clustering data. This data
        was read in the read_xy_dims() method in Section A

        Returns
        -------
        the number of terms
        """

        return self.bydoc.get_x_count()


    def get_document_count(self):
        """
        Get the number of documents in the co-clustering data. This data
        was read in the read_xy_dims() method in Section A

        Returns
        -------
        the number of documents
        """

        return self.bydoc.get_y_count()


    def get_x_labels(self):
        """
        Get the terms and their indices (x_labels). This structure was built
        in the read_x_labels() method in Section A

        Returns
        -------
        the dictionary of term indices to their in string counterparts
        """
        return self.bydoc.get_x_labels()


    def set_x_labels(self, x_labels):
        """
        Set the terms and their indices (x_labels).

        Parameters
        ----------
        x_labels : dict from int to string
            dictionary of term indices to their in string counterparts
        """

        self.bydoc.set_x_labels(x_labels)


    def get_y_labels(self):
        """
        Get the document names and their indices (y_labels). This structure
        was built in the read_y_labels() method in Section A

        Returns
        -------
        the dictionary of document indices to their string counterparts
        """

        return self.bydoc.get_y_labels()


    def set_y_labels(self, y_labels):
        """
        Set the document names and their indices (y_labels)

        Parameters
        ----------
        y_labels : dict from int to string
            dictionary that maps from a document label to its document_index. (y_labels)
        """

        self.bydoc.set_y_labels(y_labels)


    def get_xy_cooc(self):
        """
        Get the term to document co-occurrence map structure. This is a
        dictionary from a tuple (term_index (x), document_index (y)) to the
        occurrences, or frequency, of that pair (xy_cooc). For example
        term_index_to_document_index_cooc[(0, 3)] = 4 means that term_index
        '0' occurs '4' times in document_index 3.

        This is a sparse structure so 0's are not recorded. To check for
        presence of a term, document pair entry, use:
        'if (term_index,  doc_index) in self.term_index_to_document_index_cooc'.
        This structure is built in the read_xy_cooc() method in Section A.

        Returns
        -------
        the dictionary from a tuple (term_index (x), document_index (y)) to the occurrences, or frequency, of that pair,
        known as the xy_cooc
        """

        return self.bydoc.get_xy_cooc()


    def set_xy_cooc(self, xy_cooc):
        """
        Set the term to document co-occurrence map structure. This is a
        dictionary from a tuple (term_index (x), document_index (y)) to the
        occurrences, or frequency, of that pair (xy_cooc). For example
        term_index_to_document_index_cooc[(0, 3)] = 4 means that term_index
        '0' occurs '4' times in document_index 3.

        This is a sparse structure so 0's are not recorded.
        To check for presence of a term, document pair entry, use:
        'if (term_index, doc_index) in self.term_index_to_document_index_cooc'.

        Parameters
        ----------
        xy_cooc : dict of (int, int) to int
            dictionary from a tuple (term_index (x), document_index (y)) to the occurrences, or frequency, of that pair.
        """

        self.bydoc.set_xy_cooc(xy_cooc)


    def get_ax_map(self):
        """
        Get the term_cluster_index to term indices map. This tells us which
        term clusters (a's) contain which terms (x's). This is a zero based
        system. For example, an entry in this file looks like this: '3'. Lets
        say this is on line 7 of the file, since it is a zero based counting
        system, this tells us the term_index '6' belongs to term cluster '3'.
        This structure is built in the read_xa_map() method in Section A

        Returns
        -------
        A dictionary that maps from term cluster indices to a list of term indices indicating membership in that
        term cluster
        """

        return self.bydoc.get_ax_map()


    def set_ax_map(self, ax_map):
        """
        Set the term_cluster_index to term indices map. This tells us which
        term clusters (a's) contain which terms (x's). This is a zero based
        system. For example, an entry in this file looks like this: '3'. Lets
        say this is on line 7 of the file, since it is a zero based counting
        system, this tells us the term_index '6' belongs to term cluster '3'

        Parameters
        ----------
        ax_map : dict of int to int
            dictionary to a list of terms for each of the term clusters (ax_map)
        """

        self.bydoc.set_ax_map(ax_map)


    def get_yx_map(self):
        """
        Get the document_index to term indices map structure. This structure
        is built in the read_xy_cooc() method in Section A.

        Returns
        -------
        A dictionary of document_indices to a list of term_indices
        This allows us to query which terms (x's) occur in a document (y)
        """

        return self.bydoc.get_yx_map()


    def set_yx_map(self, yx_map):
        """
        Set the document_index to term indices map structure.

        Parameters
        ----------
        yx_map : dict of int to int
            dictionary of document_indices to a list of term_indices (yx_map)
        """

        self.bydoc.set_yx_map(yx_map)


    def get_yb_map(self):
        """
        Get the document_index to document_cluster_index map structure. This
        tells us which documents (y's) belong to which document clusters
        (b's). This is a zero based system. For example, an entry in this file
        looks like this: '3'. Lets say this is on line 7 of the file,
        since it is a zero based counting system, this tells us the
        term_index '6' belongs to term cluster '3'. This structure is built
        in the read_yb_map() method in Section A.

        Returns
        -------
        A dictionary that maps from the document_index to the cluster_index (yb_map)
        """

        return self.bydoc.get_yb_map()


    def set_yb_map(self, yb_map):
        """
        Set the document_index to document_cluster_index map structure. This
        tells us which documents (y's) belong to which document clusters
        (b's). This is a zero based system. For example, an entry in this file
        looks like this: '3'. Lets say this is on line 7 of the file,
        since it is a zero based counting system, this tells us the
        term_index '6' belongs to term cluster '3'.

        Parameters
        ----------
        yb_map : dict of int to int
            dictionary that maps from the document_index to the cluster_index (yb_map)
        """

        self.bydoc.set_yb_map(yb_map)


    def get_by_map(self):
        """
        Get the document_cluster_index to document_index map structure.
        This is the opposite of the ym_map.
        This structure is built in the read_yb_map() method in Section A.

        Returns
        -------
        A dictionary that maps from a document_cluster_index to a list of document indices.
        """

        return self.bydoc.get_by_map()
        # return self.document_cluster_map


    def set_by_map(self, by_map):
        """
        Set the document_cluster_index to document_index map structure. This is the opposite of the ym_map.

        Parameters
        ----------
        by_map : dict of int to list of int
            dictionary to a list of documents for each of the document clusters (by_map)
        """

        self.bydoc.set_by_map(by_map)
        # self.document_cluster_map = by_map


    def get_ba_cooc(self):
        """
        Get the document_cluster_index to a list of tuples of
        term_cluster_index and co-occurrences structure.  The source file
        contains the sparse matrix data representing the occurrences,
        or frequency, between term_clusters (a's) and document_clusters
        (b's). An example entry in this file is 0\t3\t88. This translates to
        the terms in term_cluster_index '0' occur in the documents in
        document_cluster_index '3' a total of 88 times. This structure is
        built in the read_ab_cooc() method in Section A

        Returns
        -------
        A dictionary that maps from a document_cluster_index to a list
        of tuples of term cluster indices and frequency
        """
        return self.bydoc.get_ba_cooc()


    def set_ba_cooc(self, ba_cooc):
        """
        Set the document_cluster_index to a list of tuples of
        term_cluster_index and co-occurrences structure.  The source file
        contains the sparse matrix data representing the occurrences,
        or frequency, between term_clusters (a's) and document_clusters
        (b's). An example entry in this file is 0\t3\t88. This translates to
        the terms in term_cluster_index '0' occur in the documents in
        document_cluster_index '3' a total of 88 times.

        Parameters
        ----------
        ba_cooc : dict of (int, int) to int
            dictionary to an list of tuples of term cluster indices, to frequency. This corresponds to a ba_cooc
            matrix as we are keying on the document clusters, the columns of the matrix.
        """

        self.bydoc.set_ba_cooc(ba_cooc)


    def get_xb_cooc(self):
        """
        Get the term_index to document_cluster_index co-occurrences
        structure. This contains the sparse matrix data representing the
        occurrences, or frequency, between terms (x's) and document clusters
        (b's). An example entry in the source file is 0\t3\t88. This
        translates to term_index '0' occurs in document_cluster '3' a total
        of 88 times. This structure is built in the read_xb_cooc() method in
        Section A.

        Returns
        -------
        A dictionary that maps from a tuple of (term_index, document_cluster_index)
        to their co-occurrence frequency.
        """

        return self.bydoc.get_xb_cooc()


    def set_xb_cooc(self, xb_cooc):
        """
        Set the term_index to document_cluster_index co-occurrences
        structure. This contains the sparse matrix data representing the
        occurrences, or frequency, between terms (x's) and document clusters
        (b's). An example entry in the source file is 0\t3\t88. This
        translates to term_index '0' occurs in document_cluster '3' a total
        of 88 times.

        Parameters
        ----------
        xb_cooc : dict of (int, int) to int
            dictionary of tuples of term_indices and document_cluster_indices, to frequency. (xb_map)
        """

        self.bydoc.set_xb_cooc(xb_cooc)


    def get_bx_cooc(self):
        """
        Get the document_cluster_index to the term_indices co-occurrences
        structure. This contains the sparse matrix data representing the
        occurrences, or frequency, between terms (x's) and document clusters
        (b's). An example entry in the source file is 0\t3\t88. This
        translates to term_index '0' occurs in document_cluster '3' a total
        of 88 times. This structure is built in the read_xb_cooc() method in
        Section A.

        Returns
        -------
        A dictionary that maps from a document_cluster_index to a list
        of tuples of term_indices and their frequency.
        """

        return self.bydoc.get_bx_cooc()


    def set_bx_cooc(self, bx_cooc):
        """
        Set the document_cluster_index to the term_indices co-occurrences
        structure. This contains the sparse matrix data representing the
        occurrences, or frequency, between terms (x's) and document clusters
        (b's). An example entry in the source file is 0\t3\t88. This
        translates to term_index '0' occurs in document_cluster '3' a total
        of 88 times.

        Parameters
        ----------
        bx_cooc : dict of (int, int) to int
            dictionary to a list of tuples of term_indices, to frequency. (bx_map)
        """

        self.bydoc.set_bx_cooc(bx_cooc)


    def get_xy_pmi(self):
        """
        Get the term_index to document_index Pointwise Mutual Informaion
        measure structure. Note: some of the PMI values are negative -
        Positive PMI means that that the term is MORE likely to occur in this
        document than it is overall, negative should mean it's LESS likely to
        occur this document than it is overall, and zero means that it's AS
        likely to occur in this document as any other. This structure is
        built in the read_xy_assoc() method in Section A

        Returns
        -------
        A dictionary from term_indices to a list of tuples of document_indices
        and their relative PMI
        """

        return self.bydoc.get_xy_pmi()


    def set_xy_pmi(self, xy_pmi):
        """
        Set the term_index to document_index Pointwise Mutual Informaion
        measure structure. Note: some of the PMI values are negative -
        Positive PMI means that that the term is MORE likely to occur in this
        document than it is overall, negative should mean it's LESS likely to
        occur this document than it is overall, and zero means that it's AS
        likely to occur in this document as any other.

        Parameters
        ----------
        xy_pmi : dict from int to (int, float)
            dictionary from term_indices to a list of tuples of document_indices and their relative PMI
        """

        self.bydoc.set_xy_pmi(xy_pmi)


    def get_xb_pmi(self):
        """
        Get the term_index to document_cluster_index Pointwise Mutual
        Informaion measure structure. Note: some of the PMI values are
        negative - Positive PMI means that that the term is MORE likely to
        occur in this document cluster than it is overall, negative should
        mean it's LESS likely to occur this doc cluster than it is overall,
        and zero means that it's AS likely to occur in this doc cluster as
        any other. This structure is built in the read_xb_assoc() method in
        Section A

        Returns
        -------
        A dictionary from term_indices to a list of tuples of document_cluster_indices and their relative PMI
        """

        return self.bydoc.get_xb_pmi()


    def set_xb_pmi(self, xb_pmi):
        """
        Set the term_index to document_cluster_index Pointwise Mutual
        Informaion measure structure. Note: some of the PMI values are
        negative - Positive PMI means that that the term is MORE likely to
        occur in this document cluster than it is overall, negative should
        mean it's LESS likely to occur this doc cluster than it is overall,
        and zero means that it's AS likely to occur in this doc cluster as
        any other.

        Parameters
        ----------
        xb_pmi : dict from int to (int, float)
            dictionary from term_indices to a list of tuples of document_cluster_indices and their relative PMI
        """

        self.bydoc.set_xb_pmi(xb_pmi)


    def get_xx_divergence(self):
        """
        Get the term_index pair, as a tuple, to their measured divergence (or
        distance). An example entry from the source file is 0\t3\t0.224. This
        translates to term_index '0' and term_index '3' have a divergence
        measure of 0.224. Divergence is like distance, the smaller the
        number, the closer those two terms should be considered in meaning or
        context. This structure is built in the read_xx_assoc() method in
        Section A

        Returns
        -------
        A dictionary from a pair, as a tuple, of term indices to their relative
        divergence, or distance, from each other
        """

        return self.bydoc.get_xx_divergence()


    def set_xx_divergence(self, xx_divergence):
        """
        Set the term_index pair, as a tuple, to their measured divergence (or
        distance). An example entry from the source file is 0\t3\t0.224. This
        translates to term_index '0' and term_index '3' have a divergence
        measure of 0.224. Divergence is like distance, the smaller the
        number, the closer those two terms should be considered in meaning or
        context.

        Parameters
        ----------
        xx_divergence :  dict from int to (int, float)
            dictionary from a tuple of term indices to their relative divergence, or distance, from each other
        """

        self.bydoc.set_xx_divergence(xx_divergence)


    def get_xx_divergence_adj(self):
        """
        Get the term_index pair, as a tuple, to their measured divergence (or
        distance). An example entry from the source file is 0\t3\t0.224. This
        translates to term_index '0' and term_index '3' have a divergence
        measure of 0.224. Divergence is like distance, the smaller the
        number, the closer those two terms should be considered in meaning or
        context. This structure is built in the read_xx_assoc() method in
        Section A This structure was read from the term adjacency
        co-clustering data

        Returns
        -------
        A dictionary from a pair, as a tuple, of term indices to their relative
        divergence, or distance, from each other
        """

        return self.byadj.get_xx_divergence()


    def set_xx_divergence_adj(self, xx_divergence_adj):
        """
        Set the term_index pair, as a tuple, to their measured divergence (or
        distance). An example entry from the source file is 0\t3\t0.224. This
        translates to term_index '0' and term_index '3' have a divergence
        measure of 0.224. Divergence is like distance, the smaller the
        number, the closer those two terms should be considered in meaning or
        context. This structure should be from the term adjacency
        co-clustering data

        Parameters
        ----------
        xx_divergence_adj :  dict from int to (int, float)
            dictionary from a tuple of term indices to their relative divergence, or distance, from each other
        """

        self.byadj.set_xx_divergence(xx_divergence_adj)


    def get_x_margins(self):
        """
        Get the term totals map. This is a dictionary that maps from the term index (x) to the total number of
        occurrences for that term in the corpus.

        Returns
        -------
        dictionary that maps from the term index (x) to the total number
        of occurrences for that term in the corpus.
        """

        return self.bydoc.get_x_margins()


    def set_x_margins(self, x_margins):
        """
        Set the term totals map. This is a dictionary that maps from
        the term index (x) to the total number of
        occurrences for that term in the corpus.

        Parameters
        ----------
        x_margins : dict from int to int
            dictionary that maps from term index to the total occurrences for that term in the corps
        """

        self.bydoc.set_x_margins(x_margins)


    def get_b_margins(self):
        """
        Get the document cluster totals map. This is a dictionary that maps from
        the document clusters (b) to the
        total number of term occurrences for that document cluster.

        Returns
        -------
        dictionary that maps from the document cluster index (b)
        to the total number of term occurrences for that
        document cluster.
        """

        return self.bydoc.get_b_margins()


    def set_b_margins(self, b_margins):
        """
        Set the document cluster totals map. This is a dictionary that maps from
        the document clusters (b) to the
        total number of term occurrences for that document cluster.

        Parameters
        ----------
        b_margins : dict from int to int
            dictionary that maps from document cluster to the total term occurrences for that document cluster
        """

        self.bydoc.set_b_margins(b_margins)


# Alias for backward compatibility.
Coclustering = DoubleCoclustering


def calculate_entropy(values):
    """
    Given a list of counts, calculate the entropy. 
    If the sum of the values is 0, None is returned.

    Parameters
    ----------
    values : list of ints
        the list of values to calculate the entropy for

    Returns
    -------
    The entropy of the list of counts.
    """

    total = sum(values)
    if total == 0.0:
        print("Zero distribution passed to entropy function")
        return None
    entropy = 0
    for val in values:
        if val > 0:
            probability = float(val) / float(total)
            entropy -= probability * math.log(probability)
    return entropy


def calculate_generalized_mean(divergences, exponent):
    """
    Given a list of divergences or distances, calculate the generalized mean, except without dividing
    by the count nor taking the inverse exponent, since that should not affect the subsequent ordering
    values by the callers of this method, as long as the exponent and the size of the divergences vector
    is the same across all the calls to this method.
    This is used to measure distance between a group of items and other items.
    The goal is to get a distance that considers all elements in the group.

    Parameters
    ----------
    divergences : list of floats
        the distance or divergence between 2 elements (terms to terms or documents to documents for example)
    exponent : float
        sensitivity of the generalized mean calculation

    Returns
    -------
        the generalized mean
    """
    generalized_mean = 0.0
    for divergence in divergences:
        generalized_mean += math.pow(divergence, exponent)
    return generalized_mean


def calculate_pmi(total, row_sum, col_sum, count):
    """
    Calculate the Pointwise Mutual Information between the supplied row
    and column data. PMI is the measure used to compare orthogonal
    elements such as terms vs documents of term_clusters vs
    document_clusters. See
    https://en.wikipedia.org/wiki/Pointwise_mutual_information for details.
    Formula:
        pmi(row,col) = log(   p(row, col)   /        (p(row)      *       p(col)) )
                     = log( (count / total) /  ((row_sum / total) * (col_sum / total ))

    Parameters
    ----------
    total : int
        the total number of occurrences in the co-occurrence matrix. xyTotal.tsv holds this value
    row_sum : int
        the sum of occurrences on the specified row. the *Margs.tsv files hold this information
    col_sum : int
        the sum of occurrences on the specified column. the *Margs.tsv files hold this information
    count : int
        the number of co-occurrences between the specified row/column pair. This information can be found in the
        **Cooc.tsv files

    Returns
    -------
    the point wise mutual information between the two supplied entities
    """
    probability_row_col = count / total
    probability_row = row_sum / total
    probability_col = col_sum / total
    pmi = math.log(probability_row_col / (probability_row * probability_col))
    return pmi


def give_adjacency_data_warning(method_name):
    _logger.warning(
        f"Adjacency data was requested for {method_name}(), but that data "
        "has not been loaded. See the 'adj_input_directory' parameter "
        "for the Coclustering class")


# This class provides more or less the same basic functionality as the 
# related Java classes, plus a few extras:
# * examination of yLabels (usually for byDoc cocl) to determine whether the 
#   y value (doc file name) is one of two classes, "target" or "non-target"
# * anything else?
# If desired, we could define subclasses like ByDocCoclustering and
# ByAdjCoclustering, and/or add method names using words like term and
# document in method names instead of x and y.
class SingleCoclustering(object):
    """
    Applies equally to by_doc and by_adjacency coclusterings.
    """

    # There are a lot more we don't currently declare.
    x_labels: Dict[int, str]
    y_labels: Dict[int, str]
    xy_total: int
    yx_map: Dict[int, List[Any]]  # name seems off?

    # TODO May want to put the _label stuff at the DoubleCoclustering level?
    # It tends to be used with bydoc clusterings.
    def __init__(self, input_directory, 
                 target_label=None, non_target_label=None):
        """
        Parameters
        ----------
        input_directory - path to the coclustering files where artifacts such as xyCooc.tsv live
        target_label - (optional) the string in the yLabel that identifies it as a target
        non_target_label - (optional) the string in the yLabel name that identifies it as a non target
        """

        self.input_directory = input_directory
        self.target_label = target_label
        self.non_target_label = non_target_label

        # Note: After construction you should call the data load methods:
        #   read_cooc_input_data()
        #   read_cocl_output_data()
        #   read_cocl_association_data()
        # to populate the data structures. This is no
        # longer done automatically to allow a skeleton data load
        # for specific applications.


    # Or else use kwargs in the more typical way.
    def _add_attrs(self, kwargs: Dict[str, Any], *attrs: str):
        """
        Add any parameters provided to this method to 'self'

        Parameters
        ----------
        kwargs
            keyword argument values provided during construction
        attrs
            parameter names that should be queried for addition to 'self' if they are present
        """
        for attr in attrs:
            if attr in kwargs:
                setattr(self, attr, kwargs[attr])


    def read_cooc_input_data(self):
        """
        Calls a read function for the co-occurrence data. This data is used
        to drive the co-clustering algorithm. Each of the methods below reads
        in a particular file. For example, read_xy_cooc reads and ingests the
        xyCooc.tsv file.

        Each structure that is populated by the read method is initialized
        and explained before the call to the read method.
        """
        # TODO: Change so we are loading from a tgz instead of a direcory of files
        # This is dictionary that maps from a term_index to its term label. (x_labels)
        # For example self.x_labels[0] = 'dog'
        self.x_labels = self.read_x_labels()

        # This is dictionary that maps from a document label to its y_index. (y_labels)
        # For example self.y_labels[0] = 'doc1.txt'
        self.y_labels = self.read_y_labels()

        # - self.yx_map is a dictionary of y_indices to a list
        #   of x_indices (yx_map). This allows us to
        #   query which terms (x's) occur in a document (y)
        # - self.x_index_to_y_index_cooc is a dictionary from a tuple
        #   (x_index (x), y_index (y)) to
        #   the occurrences, or frequency, of that pair. (xy_cooc).
        #   For example x_index_to_y_index_cooc[(0, 3)] = 4 means that
        #   x_index '0' occurs '4' times in y_index 3.
        #   This is a sparse structure so 0's are not recorded. To check for
        #   presence of a term, document pair entry,
        #   use: 'if (x_index, doc_index) in self.x_index_to_y_index_cooc'
        # - self.xy_total is the sum of all frequencies in the xycooc structure.
        #   This value is used for statistical calculations
        # - self.target_doc_count is a dictionary from x_indices to a list
        #   of target labelled documents they appear
        #   in. This is only populated if the target_label and non_target_label
        #   parameters are provided at construction.
        # - self.non_target_doc_count is a dictionary from x_indices
        #   to a list of non-target labelled documents they
        #   appear in. This is only populated if the target_label and
        #   non_target_label parameters are provided at construction.
        self.yx_map, self.x_index_to_y_index_cooc, self.xy_total, self.target_doc_count, \
            self.non_target_doc_count = self.read_xy_cooc()

        # - self.y_count is the number of documents in the co-occurrence
        #   data. This is also derivable from
        #   structures such as the xy_cooc but we will read it in
        #   for completeness and to ensure consistency
        # - self.x_count is the number of terms in the co-occurrence data.
        #   This is also derivable from structures such as the xy_cooc
        # but we will read it in for completeness and to ensure consistency
        self.x_count, self.y_count = self.read_xy_dims()


    def read_cocl_output_data(self):
        """
        Calls a read function for the co-clustering output data. This data is
        produced by the co-clustering algorithm. The data structures that are
        populated by these methods can also be populated by setter methods
        directly. Each structure that is populated by the read method is
        explained before the call to the read method.
        """

        # - self.x_cluster_count is an integer representing the number of term clusters
        # - self.y_cluster_count is an integer representing the number of document clusters
        self.x_cluster_count, self.y_cluster_count = self.read_ab_dims()

        # - self.y_cluster_to_x_cluster is a dictionary to a list
        #   of tuples of term cluster indices, to frequency.
        #   This corresponds to a ba_cooc matrix as we are keying on the
        #   document clusters, the columns of the matrix.
        # - self.y_cluster_entropy is a dictionary from document cluster
        #   index to its entropy measure.
        self.y_cluster_to_x_cluster, self.y_cluster_entropy = self.read_ab_cooc()

        # - self.x_cluster_to_x_map is a dictionary to a list of xs
        # for each of the term clusters (ax_map)
        # - self.x_to_x_cluster_map is a dictionary from term index
        # to term cluster index (xa_map)
        self.x_cluster_to_x_map, self.x_to_x_cluster_map = \
            self.read_xa_map()

        # - self.y_cluster_and_x_indices_to_frequency is a dictionary
        #   to a list of tuples of x_indices,
        #   to frequency. (bx_map)
        # - self.x_index_and_y_cluster_index_to_frequency is a dictionary
        #   of tuples of x_indices and
        #   y_cluster_indices, to frequency. (xb_map)
        self.y_cluster_and_x_indices_to_frequency, self.x_index_and_y_cluster_index_to_frequency = \
            self.read_xb_cooc()

        # - self.y_cluster_map is a dictionary to a list of documents
        #   for each of the document clusters (by_map)
        # - self.y_to_y_cluster_map is a dictionary that maps
        #   from the y_index to the cluster_index
        #   (yb_map)
        self.y_cluster_map, self.y_to_y_cluster_map = self.read_yb_map()

        # - self.x_totals_map is a dictionary from x_index
        #   to the row total for that term (x_margins)
        self.x_totals_map = self.read_x_margins()

        # - self.y_cluster_totals_map is a dictionary from
        #   y_cluster_index to the column total for that
        #   document cluster (b_margins)
        self.y_cluster_totals_map = self.read_b_margins()


    def read_cocl_association_data(self):
        """
        Calls a read function for the post co-clustering generated files.
        These are additional data structures that are not generated during
        the standard co-clustering algorithm 
        (see com.sri.jminer.cli.Associations in the java code).
        Not all the data is read in here.
        """

        # - self.x_to_y_cluster_pmi is a dictionary
        #   from x_indices to a list of tuples of
        #   y_cluster_indices and their relative PMI
        self.x_to_y_cluster_pmi = self.read_xb_assoc()

        # - self.x_to_y_pmi is a dictionary from x_indices
        #   to a list of tuples of y_indices and
        #   their relative PMI
        self.x_to_y_pmi = self.read_xy_assoc()

        # - self.x_to_x_divergence is a dictionary from a tuple
        #   of term indices to their relative divergence, or distance, from each other.
        self.x_to_x_divergence = self.read_xx_assoc()

        # - self.y_cluster_to_y_cluster_divergence is a dictionary
        #   from a tuple of document cluster indices to their
        #   relative divergence, or distance, from each other.
        self.y_cluster_to_y_cluster_divergence = self.read_bb_assoc()


    """
    Section A. 
    The methods below read the Co-Clustering data into 
    structures that allow them to be queried in interesing ways (see Section 
    B). They also populate direct access structures for clients that want the 
    raw data (see Section C)
    """

    # This method returns values rather than setting fields.
    def read_xy_dims(self):
        """
        Read the xyDims.tsv file. This contains the number of xs and
        the number of ys in the co-occurrence data.
        This data is added to 2 module member variables:
            self.x_count
            self.y_count
        """
        xy_dims_file_path = "%s/xyDims.tsv" % self.input_directory
        with open(xy_dims_file_path, 'r') as xy_dims_file:
            xy_dims_reader = xy_dims_file.readlines()
            # Get the term count
            x_count = int(xy_dims_reader[0].strip())
            # Get the document count
            y_count = int(xy_dims_reader[1].strip())
        return x_count, y_count


    def read_x_labels(self):
        """
        Read the xLabels.tsv file. This contains the terms in the corpus
        (x's) used as input to co-clustering. This is a 0 based numbering
        system. For example, the term, say 'dog' on line 1 will have a
        x_index of 0. This x_index is used to index structures such as
        the xyCooc.tsv.
        """
        # This is dictionary that maps from a x_index to its term label. (x_labels)
        # For example x_labels[0] = 'dog'
        x_labels = dict()
        x_labels_file_path = "%s/xLabels.tsv" % self.input_directory
        with open(x_labels_file_path, 'r') as x_labels_file:
            x_labels_reader = x_labels_file.readlines()
            for label_index in range(len(x_labels_reader)):
                x_labels[label_index] = x_labels_reader[label_index].strip()
        return x_labels


    def read_y_labels(self):
        """
        Read the yLabels.tsv file. This contains the names of the documents
        (y's) used in the co-clustering run. This is a 0 based numbering
        system. For example, the document, say doc1.txt on line 1 will have a
        y_index of 0. This y_index is used to index structures
        such as the xyCooc.tsv.
        """

        # This is dictionary that maps from a document label to its y_index. (y_labels)
        # For example y_labels[0] = 'doc1.txt'
        y_labels = dict()
        ylabels_file_path = "%s/yLabels.tsv" % self.input_directory
        with open(ylabels_file_path, 'r') as ylabels_file:
            ylabels_reader = ylabels_file.readlines()
            for label_index in range(len(ylabels_reader)):
                y_labels[label_index] = ylabels_reader[label_index].strip()
        return y_labels


    # This does some extra processing, beyond the usual cocl stuff, 
    # to deal with the target/non-target business.
    # TODO Consider better separating that out from the usual stuff.
    # Possibly also move it from the Single to the Double level
    # or for a Single subclass like ByDoc.
    def read_xy_cooc(self):
        """
        Reads the xyCooc.tsv file. This contains the sparse matrix data
        representing the occurrences, or frequency, between terms (x's) and
        documents (y's). An example entry in this file is 0\t3\t88. This
        translates to x_index '0' occurs in y_index '3' a total of
        88 times.
        """

        # dictionary from x_indices to a list of target labelled documents they appear in. This is only populated if
        # the target_label and non_target_label parameters are provided at construction.
        target_doc_count = dict()
        # dictionary from x_indices to a list of non-target labelled documents they appear in. This is only populated
        # if the target_label and non_target_label parameters are provided at construction.
        non_target_doc_count = dict()
        # sum of all frequencies in the xycooc structure. This value is used for statistical calculations
        xy_total = 0
        # dictionary of y_indices to a list of x_indices (yx_map). This allows us to query which terms (x's)
        # occur in a document (y)
        yx_map = dict()
        # dictionary from a tuple (x_index (x), y_index (y)) to the occurrences, or frequency, of that pair.
        # (xy_cooc). For example x_index_to_y_index_cooc[(0, 3)] = 4 means that x_index '0' occurs '4'
        # times in y_index 3. This is a sparse structure so 0's are not recorded. To check for presence of a
        # term, document pair entry, use: 'if (x_index, y_index) in self.x_index_to_y_index_cooc'
        x_index_to_y_index_cooc = dict()

        xy_cooc_file_path = "%s/xyCooc.tsv" % self.input_directory
        with open(xy_cooc_file_path, 'r') as xy_cooc_file:
            xy_cooc_reader = xy_cooc_file.readlines()
            for entry in xy_cooc_reader:
                parts = entry.split("\t")
                x_index = int(parts[0].strip())
                y_index = int(parts[1].strip())
                frequency = int(parts[2].strip())
                xy_total += frequency
                # This is the raw xycooc data structure. It maps from a tuple of x_index and y_index to the
                # frequency of that term in that document. This is a sparse structure so 0's are not stored
                x_index_to_y_index_cooc[(x_index, y_index)] = frequency

                y_label = self.y_labels[y_index]
                if self.target_label is not None and self.non_target_label is not None:
                    if self.target_label in y_label:
                        if x_index not in target_doc_count:
                            target_doc_count[x_index] = list()
                        target_doc_count[x_index].append(y_index)
                    elif self.non_target_label in y_label:
                        if x_index not in non_target_doc_count:
                            non_target_doc_count[x_index] = list()
                        non_target_doc_count[x_index].append(y_index)
                    else:
                        _logger.warning(f"Document {y_label} is not tagged as target or non-target")

                if y_index not in yx_map:
                    yx_map[y_index] = list()
                yx_map[y_index].append(x_index)
        return yx_map, x_index_to_y_index_cooc, xy_total, target_doc_count, non_target_doc_count


    def read_ab_dims(self):
        """
        Read the abDims.tsv file. This contains the number of term clusters
        and the number of document clusters. This data is added to
        2 module member variables:
            self.x_cluster_count
            self.y_cluster_count
        """
        ab_dims_file_path = "%s/abDims.tsv" % self.input_directory
        with open(ab_dims_file_path, 'r') as ab_dims_file:
            ab_dims_reader = ab_dims_file.readlines()
            # Get the term cluster count
            x_cluster_count = int(ab_dims_reader[0].strip())
            # Get the document cluster count
            y_cluster_count = int(ab_dims_reader[1].strip())
        return x_cluster_count, y_cluster_count


    def read_ab_cooc(self):
        """
        Reads the abCooc.tsv file. This contains the sparse matrix data
        representing the occurrences, or frequency, between x_clusters (
        a's) and y_clusters (b's). An example entry in this file is
        0\t3\t88. This translates to the terms in x_cluster_index '0'
        occur in the documents in y_cluster_index '3' a total of 88
        times.
        """

        # dictionary to an list of tuples of term cluster indices, to frequency. This corresponds to a ba_cooc
        # matrix as we are keying on the document clusters, the columns of the matrix.
        y_cluster_to_x_cluster = dict()
        ab_cooc_file_path = "%s/abCooc.tsv" % self.input_directory
        with open(ab_cooc_file_path, 'r') as ab_cooc_file:
            ab_cooc_reader = ab_cooc_file.readlines()
            for entry in ab_cooc_reader:
                parts = entry.split("\t")
                x_cluster_index = int(parts[0].strip())
                y_cluster_index = int(parts[1].strip())
                frequency = int(parts[2].strip())

                if y_cluster_index not in y_cluster_to_x_cluster:
                    # print(f"Adding the document cluster index: {y_cluster_index}")
                    y_cluster_to_x_cluster[y_cluster_index] = list()
                y_cluster_to_x_cluster[y_cluster_index].append((x_cluster_index, frequency))

        # Now that we have the numbers we need, lets pre-calculate
        # the entropy for each of the document clusters:
        y_cluster_entropy = dict()
        # print(f"Number of document clusters: {self.get_y_cluster_count()}")
        # print(f"Number of document cluster to term clusters: {len(y_cluster_to_x_cluster)}")
        for index in range(self.get_y_cluster_count()):
            # print(f"Index is: {index}")
            # sometimes we get an empty document which can cause it
            # to be dropped into a document cluster by itself.
            # this also means there are no terms, so there is no entry
            # for this document cluster in the ab_cooc - this
            # check makes sure we do not blow up as a result.
            if index in y_cluster_to_x_cluster:
                values = [x[1] for x in y_cluster_to_x_cluster[index]]
                y_cluster_entropy[index] = calculate_entropy(values=values)
            else:
                y_cluster_entropy[index] = None

        return y_cluster_to_x_cluster, y_cluster_entropy


    def read_xa_map(self):
        """
        Reads the xaMap.tsv file. This tells us which terms (x's) belong to
        which term clusters (a's). This is a zero based system. For example,
        an entry in this file looks like this: '3'. Lets say this is on line
        7 of the file, since it is a zero based counting system, this tells
        us the x_index '6' belongs to term cluster '3'.
        """

        # This is a dictionary to a list of terms for each of the term clusters (ax_map)
        x_cluster_to_x_map = dict()
        # This is a dictionary from term index to term cluster index (xa_map)
        x_to_x_cluster_map = dict()
        xa_map_file_path = "%s/xaMap.tsv" % self.input_directory
        with open(xa_map_file_path, 'r') as xa_map_file:
            xa_map_reader = xa_map_file.readlines()
            for x_number in range(len(xa_map_reader)):
                cluster_number = int(xa_map_reader[x_number].strip())
                if cluster_number not in x_cluster_to_x_map:
                    x_cluster_to_x_map[cluster_number] = list()
                x_cluster_to_x_map[cluster_number].append(x_number)
                x_to_x_cluster_map[x_number] = cluster_number
        return x_cluster_to_x_map, x_to_x_cluster_map


    def read_yb_map(self):
        """
        Read the ybMap.tsv file. This tells us which documents (y's) belong
        to which document clusters (b's). This is a zero based system. For
        example, an entry in this file looks like this: '3'. Lets say this is
        on line 7 of the file, since it is a zero based counting system,
        this tells us the x_index '6' belongs to term cluster '3'.
        """
        # This is a dictionary to a list of documents for each of the document clusters (by_map)
        y_cluster_map = dict()
        # This is a dictionary that maps from the y_index to the cluster_index (yb_map)
        y_to_y_cluster_map = dict()
        yb_map_file_path = "%s/ybMap.tsv" % self.input_directory
        with open(yb_map_file_path, 'r') as yb_map_file:
            yb_map_reader = yb_map_file.readlines()
            for y_number in range(len(yb_map_reader)):
                cluster_number = int(yb_map_reader[y_number].strip())
                if cluster_number not in y_cluster_map:
                    y_cluster_map[cluster_number] = list()
                y_cluster_map[cluster_number].append(y_number)
                y_to_y_cluster_map[y_number] = cluster_number
        return y_cluster_map, y_to_y_cluster_map


    def read_xb_cooc(self):
        """
        Reads the xbCooc.tsv file. This contains the sparse matrix data
        representing the occurrences, or frequency, between terms (x's) and
        document clusters (b's). An example entry in this file is 0\t3\t88.
        This translates to x_index '0' occurs in y_cluster '3' a
        total of 88 times.
        """
        # TODO: Low priority - change this structure to a tuple as key - they we would be able to get rid of the
        #  transpose method.
        # dictionary to a list of tuples of x_indices, to frequency. (bx_map)
        y_cluster_and_x_indices_to_frequency = dict()
        # dictionary of tuples of x_indices and y_cluster_indices, to frequency. (xb_map)
        x_index_and_y_cluster_index_to_frequency = dict()
        xb_cooc_file_path = "%s/xbCooc.tsv" % self.input_directory
        with open(xb_cooc_file_path, 'r') as xb_cooc_file:
            xb_cooc_reader = xb_cooc_file.readlines()
            for entry in xb_cooc_reader:
                parts = entry.split("\t")
                x_index = int(parts[0].strip())
                y_cluster_index = int(parts[1].strip())
                frequency = int(parts[2].strip())

                x_index_and_y_cluster_index_to_frequency[(x_index, y_cluster_index)] = frequency

                if y_cluster_index not in y_cluster_and_x_indices_to_frequency:
                    y_cluster_and_x_indices_to_frequency[y_cluster_index] = list()
                y_cluster_and_x_indices_to_frequency[y_cluster_index].append((x_index, frequency))
        return y_cluster_and_x_indices_to_frequency, x_index_and_y_cluster_index_to_frequency


    def read_xy_assoc(self):
        """
        Reads the xyAssoc.tsv file. This contains the PMI score between the
        terms (x's) ands the documents (y's). An example entry in this file
        is 0\t3\t0.224. This translates to x_index '0' and document '3'
        have a pointwise mutual information measure of 0.224.

        Note: some of the PMI values are negative - Positive PMI means that
        that the term is MORE likely to occur in this document than it is
        overall, negative should mean it's LESS likely to occur this document
        than it is overall, and zero means that it's AS likely to occur in
        this document as any other.
        """

        # TODO: Low priority, but we should make the key a tuple
        #  (x_index, y_index) to the pmi as the value. This
        #  will allow us to look up either direction easily with 1 structure.
        # Dictionary from x_indices to a list of tuples of y_indices and their relative PMI
        x_to_y_pmi = dict()
        xy_assoc_file_path = "%s/xyAssoc.tsv" % self.input_directory
        with open(xy_assoc_file_path, 'r') as xy_assoc_file:
            xy_assoc_reader = xy_assoc_file.readlines()
            for entry in xy_assoc_reader:
                parts = entry.split("\t")
                x_index = int(parts[0].strip())
                y_index = int(parts[1].strip())
                pmi = float(parts[2].strip())

                if x_index not in x_to_y_pmi:
                    x_to_y_pmi[x_index] = list()
                x_to_y_pmi[x_index].append((y_index, pmi))
        return x_to_y_pmi


    def read_xb_assoc(self):
        """
        Reads the xbAssoc.tsv file. This contains the PMI score between the
        terms (x's) ands the document clusters (b's). An example entry in
        this file is 0\t3\t0.224. This translates to x_index '0' and
        y_cluster '3' have a pointwise mutual information measure of
        0.224.

        Note: some of the PMI values are negative - Positive PMI means that
        that the term is MORE likely to occur in this document cluster than
        it is overall, negative should mean it's LESS likely to occur this
        doc cluster than it is overall, and zero means that it's AS likely to
        occur in this doc cluster as any other.
        """
        # TODO: Low priority: It would probably make more sense to have
        #  the key be a tuple pair of x_index and
        #  y_cluster index. Not a major priority - lets refactor it
        #  when we have some down time and the tests
        #  are more fully developed
        # Dictionary from x_indices to a list of tuples of y_cluster_indices and their relative PMI
        x_to_y_cluster_pmi = dict()
        xb_assoc_file_path = "%s/xbAssoc.tsv" % self.input_directory
        with open(xb_assoc_file_path, 'r') as xb_assoc_file:
            xb_assoc_reader = xb_assoc_file.readlines()
            for entry in xb_assoc_reader:
                parts = entry.split("\t")
                x_index = int(parts[0].strip())
                y_cluster_index = int(parts[1].strip())
                pmi = float(parts[2].strip())

                if x_index not in x_to_y_cluster_pmi:
                    x_to_y_cluster_pmi[x_index] = list()
                x_to_y_cluster_pmi[x_index].append((y_cluster_index, pmi))
        return x_to_y_cluster_pmi


    def read_xx_assoc(self):
        """
        Reads the xxAssoc.tsv file. This contains the divergence score
        between the terms (x's). An example entry in this file is
        0\t3\t0.224. This translates to x_index '0' and x_index '3'
        have a divergence measure of 0.224. Divergence is like distance,
        the smaller the number, the closer those two terms should be
        considered in meaning or context.
        """

        # Dictionary from a tuple of term indices to their relative divergence,
        # or distance, from each other.
        x_to_x_divergence = dict()
        xx_assoc_file_path = "%s/xxAssoc.tsv" % self.input_directory
        with open(xx_assoc_file_path, 'r') as xx_assoc_file:
            xx_assoc_reader = xx_assoc_file.readlines()
            for entry in xx_assoc_reader:
                parts = entry.split("\t")
                term1_index = int(parts[0].strip())
                term2_index = int(parts[1].strip())
                divergence = float(parts[2].strip())
                # This is incorrect.
                # Since the divergences are symmetrical we only need to store
                # them in one direction - always lead with the smallest index
                # if term1_index < term2_index:
                #     key = (term1_index, term2_index)
                # else:
                #     key = (term2_index, term1_index)
                key = (term1_index, term2_index)
                x_to_x_divergence[key] = divergence
        return x_to_x_divergence


    def read_bb_assoc(self):
        """
        Reads the bbAssoc.tsv file. This contains the divergence score
        between the document clusters (b's). An example entry in this file is
        0\t3\t0.224. This translates to y_cluster '0' and y_cluster '3'
        have a divergence measure of 0.224. Divergence is like distance,
        the smaller the number, the closer those two document clusters should
        be considered in meaning or context.
        """

        # Dictionary from a tuple of document cluster indices to their relative
        # divergence, or distance, from each other.
        y_cluster_to_y_cluster_divergence = dict()
        bb_assoc_file_path = "%s/bbAssoc.tsv" % self.input_directory
        with open(bb_assoc_file_path, 'r') as bb_assoc_file:
            bb_assoc_reader = bb_assoc_file.readlines()
            for entry in bb_assoc_reader:
                parts = entry.split("\t")
                y_cluster_1_index = int(parts[0].strip())
                y_cluster_2_index = int(parts[1].strip())
                divergence = float(parts[2].strip())
                # This is incorrect.
                # Since the divergences are symmetrical we only need to store
                # them in one direction - always lead with the smallest index
                # if y_cluster_1_index < y_cluster_2_index:
                #     key = (y_cluster_1_index, y_cluster_2_index)
                # else:
                #     key = (y_cluster_2_index, y_cluster_1_index)
                key = (y_cluster_1_index, y_cluster_2_index)
                y_cluster_to_y_cluster_divergence[key] = divergence
        return y_cluster_to_y_cluster_divergence


    def read_x_margins(self):
        """
        Read the xMargs.tsv file. This holds the row totals that correspond
        to how many times each term (x) appears in the corpus. An example of
        this in the file is '849' on first line. This means that the term
        with index '0' occurred 849 times in the entire set of documents.
        """
        # This is a dictionary that maps from the x_index to the count for that term
        x_counts_map = dict()
        x_counts_file = "%s/xMargs.tsv" % self.input_directory
        with open(x_counts_file, 'r') as x_margins_file:
            x_margins_reader = x_margins_file.readlines()
            for x_index in range(len(x_margins_reader)):
                x_count = int(x_margins_reader[x_index].strip())
                x_counts_map[x_index] = x_count
        return x_counts_map


    def read_b_margins(self):
        """
        Read the bMargs.tsv file. This holds the column totals that
        correspond to how many times each of the terms (x's) occur in each
        document cluster (b). An example of this in the file is '6265' on
        first line. This means that the y_cluster with index '0' had a
        total term occurrence of 6265.
        """
        # This is a dictionary that maps from the y_cluster_index
        # to the count for that document cluster
        y_cluster_counts_map = dict()
        y_cluster_counts_file = "%s/bMargs.tsv" % self.input_directory
        with open(y_cluster_counts_file, 'r') as b_margins_file:
            b_margins_reader = b_margins_file.readlines()
            for y_cluster_index in range(len(b_margins_reader)):
                x_occurrences_count = int(b_margins_reader[y_cluster_index].strip())
                y_cluster_counts_map[y_cluster_index] = x_occurrences_count
        return y_cluster_counts_map


    """
    Section B.
    The methods below give access to the massaged data in the 
    CoClustering structure. For instance they offer access to sorted lists of 
    associations between various structures such as the list of terms most 
    aligned with a specific document cluster for instance. For direct to the 
    underlying structures, see Section C
    """

    def get_x_cluster_count(self):
        """
        Get the number of term clusters in the co-clustering data

        Returns
        -------
        The number of term clusters in the co-clustering data
        """
        return self.x_cluster_count


    def get_y_cluster_count(self):
        """
        Get the number of document clusters in the co-clustering data

        Returns
        -------
        The number of document clusters in the co-clustering data
        """
        return self.y_cluster_count


    def get_y_count_in_cluster(self, cluster_index):
        """
        Get the number of documents that occur in the specified y_cluster_index

        Parameters
        ----------
        cluster_index : int
            The index of the y_cluster that we want to get the document count for

        Returns
        -------
        the number of documents that occur in the specified y_cluster_index
        """
        return len(self.y_cluster_map[cluster_index])


    def get_y_labels_in_y_cluster(self, y_cluster_index):
        """
        Get the list of document labels (what appears in the yLabels.tsv file)
        that belong to the specified y_cluster_index

        Parameters
        ----------
        y_cluster_index : int
            The index of the y_cluster that we want to get the assigned document labels for

        Returns
        -------
        The list of document labels that belong to the specified y_cluster_index
        """
        ys_in_cluster = list()
        for j in range(len(self.y_cluster_map[y_cluster_index])):
            # The doc index is the line number (-1) from the ylabels.tsv file.
            yindex = self.y_cluster_map[y_cluster_index][j]
            ys_in_cluster.append(self.y_labels[yindex])
        return ys_in_cluster


    def get_y_cluster_for_y_label(self, y_label):
        """
        Get the assigned y_cluster_id for the provided y_label.
       This information is stored in the  ybMap.tsv file.

        Parameters
        ----------
        y_label : string
            The label of the document (y) that we want to know the assigned y_cluster_id for

        Returns
        -------
        Assigned y_cluster_id for the provided y_label
        """
        # get the id that corresponds to this document:
        y_index = list(self.y_labels.keys())[list(self.y_labels.values()).index(y_label)]
        return self.y_to_y_cluster_map[y_index]


    def get_y_cluster_target_purity(self, y_cluster_index):
        """
        Get the % purity of the specified y_cluster_index. Purity is
        defined as the ration of target to non_target documents in the
        document cluster. Note, this feature is only available when the
        target_label and non_target_label is provided during construction.
        See the 'Using the Co-clustering class' notes at the top of this
        class for further details

        Parameters
        ----------
        y_cluster_index : int
            The index of the y_cluster that we want to get the % purity for

        Returns
        -------
        The % purity of the specified y_cluster_index
        """

        if self.target_label is None:
            return None
        y_labels_in_cluster = self.get_y_labels_in_y_cluster(y_cluster_index=y_cluster_index)
        target_count = 0
        for doc in y_labels_in_cluster:
            if self.target_label in doc:
                target_count += 1
        purity = (target_count / len(y_labels_in_cluster)) * 100
        return round(purity, 2)


    def get_y_cluster_non_target_purity(self, y_cluster_index):
        """
        Get the % non_purity of the specified y_cluster_index.
        Non-purity is defined as the ration of non-target to target documents
        in the document cluster. Note, this feature is only available when
        the target_label and non_target_label is provided during
        construction. See the 'Using the Co-clustering class' notes at the
        top of this class for further details

        Parameters
        ----------
        y_cluster_index : int
            The index of the y_cluster that we want to get the % non-purity for

        Returns
        -------
        The % non-purity of the specified y_cluster_index
        """

        if self.non_target_label is None:
            return None
        y_labels_in_cluster = self.get_y_labels_in_y_cluster(y_cluster_index=y_cluster_index)
        non_target_count = 0
        for doc in y_labels_in_cluster:
            if self.non_target_label in doc:
                non_target_count += 1
        purity = (non_target_count / len(y_labels_in_cluster)) * 100
        return round(purity, 2)


    def calculate_y_cluster_variance(self, y_cluster_index):
        """
        For a given document cluster, calculate its variance. This is a
        measure of how dissimilar its documents are from each other. A
        variance of 0.0 means that the document cluster contains 100%
        duplicate (or a total of 1) documents. The higher the variance,
        the more dissimilar the documents are from each other. This is used
        to detect boiler plate documents. See
        https://www150.statcan.gc.ca/n1/edu/power-pouvoir/ch12/5214891-eng.htm#:~: text=We%20know%20that%20variance%20is,and%20the%20variance%20is%200.667.
        for further details.
        """

        # Step 1: get the average term count for each document in the document cluster
        number_of_docs_in_cluster = self.get_y_count_in_cluster(y_cluster_index)
        number_of_terms_in_cluster = len(self.get_bx_cooc()[y_cluster_index])
        average_x_occurrences = dict()
        # for x_doc_cluster_tuple_key, frequency in self.get_xb_cooc().items():
        for x_frequency_tuple in self.get_bx_cooc()[y_cluster_index]:
            x_index = x_frequency_tuple[0]
            frequency = x_frequency_tuple[1]
            average_x_occurrences[(x_index, y_cluster_index)] = frequency / number_of_docs_in_cluster

        # Step 2: get the variance of each document from the document cluster centroid
        y_variances_from_average = dict()
        for y_index in self.get_by_map()[y_cluster_index]:
            variance = 0.0
            for x_y_cluster_tuple_key, value in average_x_occurrences.items():
                key = (x_y_cluster_tuple_key[0], y_index)
                if key in self.get_xy_cooc():
                    distance = self.get_xy_cooc()[key] - value
                    distance *= distance
                    variance += distance
            variance /= number_of_terms_in_cluster
            y_variances_from_average[y_index] = variance

        # Step 3: get the average variance
        total_variance = 0
        for y_index, variance in y_variances_from_average.items():
            total_variance += variance
        average_variance = total_variance / number_of_docs_in_cluster
        return average_variance


    def get_y_cluster_entropy(self, y_cluster_index):
        """
        Get the entropy of the specified y_cluster_index

        Parameters
        ----------
        y_cluster_index : int
            The index of the y_cluster that we want the entropy for

        Returns
        -------
        The entropy of the specified y_cluster_index
        """
        return self.y_cluster_entropy[y_cluster_index]


    def get_terms_in_doc_cluster_ordered_by_freq(self, y_cluster_index, mwus_only=False):
        """
        Get the terms and their frequency in the specified y_cluster_index

        Parameters
        ----------
        y_cluster_index : int
            The index of the y_cluster that we want the terms for
        mwus_only : bool
            If True, only return terms that are multi word units
             ('apple tree' for example), if false, return all terms

        Returns
        -------
        Sorted list of tuples of x_indices to their frequency in the
        specified y_cluster. Sorted from most frequent to least frequent

        """
        if mwus_only:
            terms = self.y_cluster_and_x_indices_to_frequency[y_cluster_index]
            mwus = list()
            for term in terms:
                if ' ' in self.get_x_labels()[term[0]]:
                    mwus.append(term)
            return sorted(mwus, key=lambda x: x[-1], reverse=True)

        return sorted(self.y_cluster_and_x_indices_to_frequency[y_cluster_index], key=lambda x: x[-1], reverse=True)


    def get_pmi_x_to_y_cluster(self, x_index, y_cluster_index):
        """
        Get the Pointwise Mutual Information measure between the specified
        x_index and y_cluster_index
        Parameters
        ----------
        x_index : int
            index of the term we want the pmi measure for
        y_cluster_index : int
            index of the y_cluster that we want the pmi measure for

        Returns
        -------
        The Pointwise Mutual Information measure between the
        specified x_index and y_cluster_index. If no value is
        available for the specified pair, None is returned.

        Note: some of the PMI values are negative - Positive PMI means that
        that the term is MORE likely to occur in this document cluster than
        it is overall, negative should mean it's LESS likely to occur this
        doc cluster than it is overall, and zero means that it's AS likely to
        occur in this doc cluster as any other.
        """
        y_cluster_pmi_tuple = self.x_to_y_cluster_pmi[x_index]
        element = [item for item in y_cluster_pmi_tuple if item[0] == y_cluster_index]
        if len(element) > 0:
            return element[0][1]
        else:
            return None


    def generate_pmi_x_to_y_cluster(self, x_index, doc_cluster):
        """
        Calculate the Pointwise Mutual Information measure between the
        specified x_index and y_cluster_index. Note: some of the
        PMI values are negative - Positive PMI means that that the term is
        MORE likely to occur in this document cluster than it is overall,
        negative should mean it's LESS likely to occur this doc cluster than
        it is overall, and zero means that it's AS likely to occur in this
        doc cluster as any other.

        Parameters
        ----------
        x_index : int
            index of the term we want the pmi measure for
        doc_cluster : int
            index of the y_cluster that we want the pmi measure for

        Returns
        -------
        The Pointwise Mutual Information measure between the specified x_index and y_cluster_index
        """
        count = self.get_xb_cooc()[(x_index, doc_cluster)]
        row_sum = self.x_totals_map[x_index]
        col_sum = self.y_cluster_totals_map[doc_cluster]
        return calculate_pmi(total=self.xy_total, row_sum=row_sum, col_sum=col_sum, count=count)


    def get_pmi_x_to_y(self, x_index, y_index):
        """
        Get the Pointwise Mutual Information measure between the specified
        x_index and doc_index

        Parameters
        ----------
        x_index : int
            index of the term we want the pmi measure for
        y_index : int
            index of the document that we want the pmi measure for

        Returns
        -------
        The Pointwise Mutual Information measure between the
        specified x_index and y_cluster_index. If no value is
        available for the specified pair, None is returned.

        Note - some of the PMI values are negative - Positive PMI means that
        that the term is MORE likely to occur in this document cluster than
        it is overall, negative should mean it's LESS likely to occur this
        doc cluster than it is overall, and zero means that it's AS likely to
        occur in this doc cluster as any other.
        """
        y_pmi_tuple = self.x_to_y_pmi[x_index]
        element = [item for item in y_pmi_tuple if item[0] == y_index]
        if len(element) > 0:
            return element[0][1]
        else:
            return None


    def get_document_text(self, document_label):
        """
        Get the text of the document (y) with the specified label.

        Parameters
        ----------
        document_label : string
            THe label of the document that we want the text for.

        Returns
        -------
        The text contents of the specified document. The data is returned
        as a single string, all carriage returns are replaced by spaces.
        """
        document_path = "%s/docs/%s" % (self.input_directory, document_label)
        data = ""
        with open(document_path, 'r') as file:
            data = file.read().replace('\n', ' ')
        return data


    def get_target_y_count_for_xs(self, terms):
        """
        Get the number of target and non-target documents that the specified
        terms occur in. Note, this feature is only available when the
        target_label and non_target_label is provided during construction.
        See the 'Using the Co-clustering class' notes at the top of this
        class for further details.

        Parameters
        ----------
        terms : list of string
            list of terms that we want to get a target and non-target document count for

        Returns
        -------
        The number of target documents the terms occur in and
        the number of non-target documents the terms occur in. Documents are
        not double counted, if 2 terms occur in the same document it is
        included in the count only once.
        """

        target_doc_count = set()
        non_target_doc_count = set()
        for term in terms:
            index_of_term = list(self.get_x_labels().keys())[list(self.get_x_labels().values()).index(term)]
            # First make sure the term index is present - it may not be in any target documents
            if index_of_term in self.target_doc_count:
                target_doc_count.update(self.target_doc_count[index_of_term])
            # First make sure the term index is present - it may not be in any non-target documents
            if index_of_term in self.non_target_doc_count:
                non_target_doc_count.update(self.non_target_doc_count[index_of_term])
        return len(target_doc_count), len(non_target_doc_count)


    def get_x_index_from_x_label(self, term):
        """
        Convenience function that returns the x_index for the provided term

        Parameters
        ----------
        term : string
            The term string that we want to get the x_index for

        Returns
        -------
        The x_index for the provided term
        """
        # TODO? This is quite slow, and there is similar code elsewhere
        # in this file. Unless we want to trade more time for less space,
        # we should be able to use existing data structures for this (?),
        # or build them ourselves.
        return list(self.get_x_labels().keys())[list(self.get_x_labels().values()).index(term)]


    def get_x_to_x_divergence(self, term1, term2):
        """
        Get the divergence measure (distance) between the two specified term indices

        Parameters
        ----------
        term1 : int
            index of the first term to get the divergence measure for
        term2 : int
            index of the second term to get the divergence measure for

        Returns
        -------
        The divergence measure (distance) between the two
        specified term indices. The divergence map may have been pruned,
        leaving open the possibility that no divergence is recorded for a
        given pair of terms.  In that case, return a very high divergence.
        """

        MILES_APART = 50.0
        # The divergence between a term and itself is 0.0
        if term1 == term2:
            return 0
        # This is incorrect.
        # Since the divergences are symmetrical we only need to store them
        # in one direction - always lead with the smallest index
        # if term1 < term2:
        #     key = (term1, term2)
        # else:
        #     key = (term2, term1)
        key = (term1, term2)
        try:
            return self.x_to_x_divergence[key]
        except KeyError:
            return MILES_APART


    def get_y_cluster_to_y_cluster_divergence(self, y_cluster_1, y_cluster_2):
        """
        Get the divergence measure (distance) between the two specified document cluster indices

        Parameters
        ----------
        y_cluster_1 : int
            index of the first document cluster to get the divergence measure for
        y_cluster_2 : int
            index of the second document cluster to get the divergence measure for

        Returns
        -------
        The divergence measure (distance) between the two specified document cluster indices
        """

        MILES_APART = 50.0
        # The divergence between a term and itself is 0.0
        if y_cluster_1 == y_cluster_2:
            return 0
        # This is incorrect.
        # Since the divergences are symmetrical we only need to store them
        # in one direction - always lead with the smallest index
        # if y_cluster_1 < y_cluster_2:
        #     key = (y_cluster_1, y_cluster_2)
        # else:
        #     key = (y_cluster_2, y_cluster_1)
        key = (y_cluster_1, y_cluster_2)
        if key in self.y_cluster_to_y_cluster_divergence:
            return self.y_cluster_to_y_cluster_divergence[key]
        else:
            return MILES_APART


    def get_x_cluster_siblings_sorted_by_divergence(self, x_index, limit=20):
        """
        Get a list of x_indices, sorted by divergence, from closest
        to furthest, in the same term cluster as the specified x_index.

        Parameters
        ----------
        x_index : int
            the x_index to get the sorted list of x_cluster siblings for
        limit : int
            the number of term siblings that should be returned. The default value here is 20.

        Returns
        -------
        List of x_indices, sorted by divergence, from closest to furthest,
        in the same term cluster as the specified x_index.
        """
        # Get the term cluster this term belongs to
        x_cluster_index = self.get_x_cluster_for_x_index(x_index=x_index)
        # Get the terms from the term cluster and get their divergence from the supplied term
        terms = self.x_cluster_to_x_map[x_cluster_index]

        siblings = list()
        for term in terms:
            # We dont want to compare the provided term to itself
            if term == x_index:
                continue
            divergence = self.get_x_to_x_divergence(term1=x_index, term2=term)
            siblings.append((term, divergence))

        # Reverse is false since we want the smallest distances listed first
        return sorted(siblings, key=lambda x: x[-1], reverse=False)[0:limit]


    def get_y_clusters_sorted_by_divergence(self, y_cluster_index):
        """
        Get a list of y_cluster_indices, sorted by divergence,
        from closest to furthest from the specified document cluster

        Parameters
        ----------
        y_cluster_index : int
            the document cluster to compare to the other document clusters

        Returns
        -------
        List of document cluster indices, sorted by divergence, from closest
        to furthest from the specified document cluster
        """
        siblings = list()
        for cluster_index in range(self.y_cluster_count):
            # We dont want to compare the provided term to itself
            if cluster_index == y_cluster_index:
                continue
            divergence = self.get_y_cluster_to_y_cluster_divergence(y_cluster_1=y_cluster_index,
                                                                        y_cluster_2=cluster_index)
            siblings.append((cluster_index, divergence))

        # Reverse is false since we want the smallest distances listed first
        return sorted(siblings, key=lambda x: x[-1], reverse=False)


    def rank_y_clusters_against_multiple_y_cluster(self, y_clusters, exponent=0.1):
        """
        Given a group of document clusters, rank the other document clusters
        against them from closest to farthest. This method uses the
        generalized mean algorithm
        https://en.wikipedia.org/wiki/Generalized_mean which was suggested by
        John Niekrasz and Bob Sasseen. This mechanism allows us to measure
        distance between each document cluster and the provided group as a
        whole.

        Parameters
        ----------
        y_clusters : list of ints
            the indices of the document clusters we want to compare to all other document clusters
        exponent : float
            sensitivity of the generalized mean calculation

        Returns
        -------
            list of lists of document cluster indices to their generalized
            mean distance to the group of document
            clusters provided. Sorted from nearest to farthest
        """
        all_divergences = list()
        for index in y_clusters:
            divergences = list()
            for cluster_index in range(self.y_cluster_count):
                # We don't want to compare the provided document clusters to themselves
                if cluster_index in y_clusters:
                    continue
                divergence = self.get_y_cluster_to_y_cluster_divergence(
                    y_cluster_1=index, y_cluster_2=cluster_index)
                divergences.append([cluster_index, divergence])
            all_divergences.append(divergences)

        generalized_means = list()
        for cluster_index in range(self.y_cluster_count):
            # We don't want to compare the provided document clusters to themselves
            if cluster_index in y_clusters:
                continue

            # Get the index of the cell we want
            index = -1
            for div_index in range(len(all_divergences[0])):
                if all_divergences[0][div_index][0] == cluster_index:
                    index = div_index
                    break

            divergences_for_cluster = list()
            for divergences in all_divergences:
                divergences_for_cluster.append(divergences[index][1])

            generalized_mean = calculate_generalized_mean(divergences_for_cluster, exponent)
            generalized_means.append([cluster_index, generalized_mean])

        return sorted(generalized_means, key=lambda x: x[-1], reverse=False)


    def rank_xs_nearest_to_select_xs(self, x_indices, exponent=0.1, limit=200):
        """
        Given a group of xs, rank the other xs against them from
        closest to farthest. This method uses the generalized mean algorithm
        https://en.wikipedia.org/wiki/Generalized_mean which was suggested by
        John Niekrasz and Bob Sasseen. This mechanism allows us to measure
        distance between each term and the provided group of xs as a whole.

        Parameters
        ----------
        x_indices : list of ints
            the indices of xs that we want to compare to all other xs as a group
        exponent : float
            sensitivity of the generalized mean calculation
        limit : int
            maximum number of xs to return


        Returns
        -------
            list of lists of term indices to their generalized mean distance
            to the group of xs provided. Sorted from
            nearest to farthest
        """
        all_divergences = list()
        for index in x_indices:
            divergences = list()
            for x_index in range(len(self.get_x_labels())):
                # We don't want to compare the provided document clusters to themselves
                if x_index in x_indices:
                    continue
                divergence = self.get_x_to_x_divergence(term1=index, term2=x_index)
                divergences.append([x_index, divergence])
            all_divergences.append(divergences)

        generalized_means = list()
        for x_index in range(len(self.get_x_labels())):
            # We don't want to compare the provided terms to themselves
            if x_index in x_indices:
                continue

            # Get the index of the cell we want
            index = -1
            for div_index in range(len(all_divergences[0])):
                if all_divergences[0][div_index][0] == x_index:
                    index = div_index
                    break

            divergences_for_xs = list()
            for divergences in all_divergences:
                divergences_for_xs.append(divergences[index][1])

            generalized_mean = calculate_generalized_mean(divergences_for_xs, exponent)
            generalized_means.append([x_index, generalized_mean])

        return sorted(generalized_means, key=lambda x: x[-1], reverse=False)[0:limit]


    def rank_y_clusters_nearest_to_select_xs(self, x_indices):
        """
        Rank the document clusters by PMI with the provided terms. This
        feature allows the caller to identify document clusters that have a
        high correlation with the supplied terms when considered together.

        Algorithm being applied (compliments of Bob Sasseen):
                scores = array(# of Bs)
                for all Bs
                  scores[B] = 0
                  sumwts = 0
                  for all Xs in your term set
                     wt = XBCooc(X,B) / XYTotal
                     scores[B] += xbPmi(X,B) * wt
                     sumwts += wt
                  // end for X
                  scores[B] /= sumwts
                // end for B

        Parameters
        ----------
        x_indices : list of int
            list of x_indices that we want to measure against document clusters.

        Returns
        -------
        List of tuples from document cluster index to their pmi measure against the supplied x_indices
        """

        # TODO: Medium priority: this and the following method
        #  rank_xs_nearest_to_select_y_clusters() looks to be
        #  producing meaningful results when we look at them in the jupyter
        #  notebook. However, apart from checking the ordering it would be
        #  nice to have a couple tests that ensure top
        #  xs/y_clusters that occur near all supplied
        #  y_clusters/xs are surfaced
        scores = list()
        for cluster_index in range(self.y_cluster_count):
            sum_of_weights = 0.0
            scores.append([cluster_index, 0.0])
            for x_index in x_indices:
                key = (x_index, cluster_index)
                if key not in self.x_index_and_y_cluster_index_to_frequency:
                    continue
                weight = self.x_index_and_y_cluster_index_to_frequency[key] / self.xy_total
                scores[cluster_index][1] += weight * self.get_pmi_x_to_y_cluster(
                    x_index=x_index, y_cluster_index=cluster_index)
                sum_of_weights += weight
            if sum_of_weights == 0:
                scores[cluster_index][1] = 0
            else:
                scores[cluster_index][1] /= sum_of_weights

        return sorted(scores, key=lambda x: x[-1], reverse=True)


    def rank_xs_nearest_to_select_y_clusters(self, y_cluster_indices, limit=50):
        """
        Rank the xs by PMI with the provided document clusters. This
        feature allows the caller to identify xs that have a high
        correlation with the supplied document clusters when considered
        together.

        Algorithm being applied (compliments of Bob Sasseen):
                scores = array(# of X)
                for all Xs
                  scores[X] = 0
                  sumwts = 0
                  for all Bs in your document cluster set
                     wt = XBCooc(X,B) / XYTotal
                     scores[X] += xbPmi(X,B) * wt
                     sumwts += wt
                  // end for B
                  scores[X] /= sumwts
                // end for X
        Parameters
        ----------
        y_cluster_indices : list of int
            list of y_cluster_indices that we want to measure against xs.

        Returns
        -------
        List of tuples from document cluster index to their pmi measure
        against the supplied x_indices
        """
        scores = list()
        for x_index in range(len(self.get_x_labels())):
            sum_of_weights = 0.0
            scores.append([x_index, 0.0])
            for y_cluster_index in y_cluster_indices:
                key = (x_index, y_cluster_index)
                if key not in self.x_index_and_y_cluster_index_to_frequency:
                    continue
                weight = self.x_index_and_y_cluster_index_to_frequency[key] / self.xy_total
                scores[x_index][1] += weight * self.get_pmi_x_to_y_cluster(
                    x_index=x_index, y_cluster_index=y_cluster_index)
                sum_of_weights += weight
            if sum_of_weights == 0:
                scores[x_index][1] = 0
            else:
                scores[x_index][1] /= sum_of_weights

        return sorted(scores, key=lambda x: x[-1], reverse=True)[0:limit]


    def rank_ys_nearest_to_select_xs(self, x_indices, limit=100):
        scores = list()
        for y_index in range(len(self.y_labels)):
            sum_of_weights = 0.0
            scores.append([y_index, 0.0])
            for x_index in x_indices:
                key = (x_index, y_index)
                if key not in self.x_index_to_y_index_cooc:
                    continue
                weight = self.x_index_to_y_index_cooc[key] / self.xy_total
                scores[y_index][1] += self.get_pmi_x_to_y(
                    x_index=x_index, y_index=y_index) * weight
                sum_of_weights += weight
            if sum_of_weights == 0:
                scores[y_index][1] = 0
            else:
                scores[y_index][1] /= sum_of_weights

        return sorted(scores, key=lambda x: x[-1], reverse=True)[0:limit]


    # Probably no longer necessary but we will leave it here for now
    def choose_closest_entities(self, total_entities, comparison_entities, generalized_divergences):
        averaged_divergences = list()
        for index in range(total_entities):
            # We dont want to compare the provided document clusters to themselves
            if index in comparison_entities:
                continue
            # Get the index of the cell we want
            cluster_index = -1
            for div_index in range(len(generalized_divergences[0])):
                if generalized_divergences[0][div_index][0] == index:
                    cluster_index = div_index
                    break

            smallest_divergence = sys.float_info.max
            for divergences in generalized_divergences:
                #print(f"cluster_index = {cluster_index}")
                value = divergences[cluster_index][1]
                if value < smallest_divergence:
                    smallest_divergence = value
            averaged_divergences.append((index, smallest_divergence))
        # Reverse is false since we want the smallest distances listed first
        return sorted(averaged_divergences, key=lambda x: x[-1], reverse=False)


    def get_x_cluster_for_x_index(self, x_index):
        """
        Get the x_cluster_index that the specified x_index is assigned to.

        Parameters
        ----------
        x_index : int
            x_index that we want the assigned x_cluster_index for

        Returns
        -------
        The x_cluster_index that the specified x_index is assigned to
        """
        return self.x_to_x_cluster_map[x_index]


    def get_closest_xs_sorted_by_divergence(self, x_index, limit=20):
        """
        Get tuples of x_indices to divergence with the specified
        x_index, sorted by closest first. Note this will compare the
        specified term to *all* xs, not only those that are in the same
        x_cluster (the x_cluster functionality is available in the
        get_x_cluster_siblings_sorted_by_divergence() method).

        Parameters
        ----------
        x_index : int
            the x_index that we want to get the closest xs for
        limit : int
            the number of term indices to return. Default is 20

        Returns
        -------
        Tuples of x_indices to divergence with the specified x_index, 
        sorted by closest first. Term count
        returned is limited by the 'limit' parameter.
        """
        closest_xs = list()
        # Get the term cluster this term belongs to
        # x_cluster_index = self.x_to_x_cluster_map[x_index]
        # Get the xs from the term cluster and get their divergence from the supplied term
        # xs = self.x_cluster_to_x_map[x_cluster_index]
        for term in self.get_x_labels():
            # We dont want to compare the provided term to itself
            if term == x_index:
                continue
            try:
                divergence = self.get_x_to_x_divergence(term1=x_index, term2=term)
                closest_xs.append((term, divergence))
            except KeyError:
                pass

        # Reverse is false since we want the smallest distances listed first
        return sorted(closest_xs, key=lambda x: x[-1], reverse=False)[0:limit]


    def get_y_cluster_counts_over_x_clusters(self, y_cluster_index):
        """
        Get the co-occurrences between the specified y_cluster_index
        and the term clusters (column in the ab_cooc structure).

        Parameters
        ----------
        y_cluster_index : int
            the index of the y_cluster that we want the x_cluster co-occurrences for

        Returns
        -------
        List of tuples from x_cluster_index to co-occurrences
        with the specified y_cluster_index
        """
        return self.y_cluster_to_x_cluster[y_cluster_index]


    # TODO This should be called something like get_xs_in_y,
    # except that at the Single level "in" in over-specific,
    # maybe use "for".
    # Formerly called get_terms_in_document.
    def get_y_to_xs(self, y_index):
        """
        Get the list of x_indices that are present in (co-occur with)
        the specified y_index. This information comes from the yx_map

        Parameters
        ----------
        y_index : int
            index of the document that we want the co-occurring term indices for

        Returns
        -------
        The list of x_indices that are present in (co-occur with) the specified y_index
        """
        return self.yx_map[y_index]


    def get_y_index_from_label(self, y_label):
        """
        Convenience method for getting the y_index that corresponds
        to the supplied y_label.

        Parameters
        ----------
        y_label : string
            the y_label of the document that we want the y_index for

        Returns
        -------
        The y_index that corresponds to the supplied y_label
        """
        return list(self.y_labels.keys())[list(self.y_labels.values()).index(y_label)]


    # This is not a great name, but x/y in the args vs y/y in the name 
    # is correct.
    def get_y_occurrences_in_y_cluster(self, x_index, y_cluster_index):
        """
        Given a x_index, find the number of documents it appears in,
        in the provided y_cluster_index. This is used to determine how
        common a term is in the documents assigned to a particular document
        cluster.

        Parameters
        ----------
        x_index : int
            index of the term to get document count for
        y_cluster_index : int
            index of the document cluster that we want a document presence count for

        Returns
        -------
        the number of documents in the specified document cluster that a term appears in.
        """

        # Get the documents assigned to the doc cluster
        documents_in_cluster = self.get_by_map()[y_cluster_index]
        # Get the term to document occurrence structure
        x_to_y_cooc = self.get_xy_cooc()
        count = 0
        for document in documents_in_cluster:
            # if the term and document co-occur, increase the doc count
            if (x_index, document) in x_to_y_cooc:
                count += 1
        return count



    """
    Section C.
    The methods below give direct access to the Co-Clustering structures such as the xy_cooc, ab_map etc. 
    """


    def get_x_count(self):
        """
        Get the number of terms in the co-clustering data. This data
        was read in the read_xy_dims() method in Section A

        Returns
        -------
        the number of terms
        """
        return self.x_count


    def get_y_count(self):
        """
        Get the number of documents in the co-clustering data. This data
        was read in the read_xy_dims() method in Section A

        Returns
        -------
        the number of documents
        """
        return self.y_count


    def get_x_labels(self):
        """
        Get the terms and their indices (x_labels). This structure was built
        in the read_x_labels() method in Section A

        Returns
        -------
        the dictionary of term indices to their in string counterparts
        """
        return self.x_labels


    def set_x_labels(self, x_labels):
        """
        Set the terms and their indices (x_labels).

        Parameters
        ----------
        x_labels : dict from int to string
            dictionary of term indices to their in string counterparts
        """
        self.x_labels = x_labels


    def get_y_labels(self):
        """
        Get the document names and their indices (y_labels). This structure
        was built in the read_y_labels() method in Section A

        Returns
        -------
        the dictionary of document indices to their string counterparts
        """
        return self.y_labels


    def set_y_labels(self, y_labels):
        """
        Set the document names and their indices (y_labels)

        Parameters
        ----------
        y_labels : dict from int to string
            dictionary that maps from a document label to its y_index. (y_labels)
        """
        self.y_labels = y_labels


    def get_xy_cooc(self):
        """
        Get the term to document co-occurrence map structure. This is a
        dictionary from a tuple (x_index (x), y_index (y)) to the
        occurrences, or frequency, of that pair (xy_cooc). For example
        x_index_to_y_index_cooc[(0, 3)] = 4 means that x_index
        '0' occurs '4' times in y_index 3.

        This is a sparse structure so 0's are not recorded. To check for
        presence of a term, document pair entry, use:
        'if (x_index,  y_index) in self.x_index_to_y_index_cooc'.
        This structure is built in the read_xy_cooc() method in Section A.

        Returns
        -------
        the dictionary from a tuple (x_index (x), y_index (y)) to the occurrences, or frequency, of that pair,
        known as the xy_cooc
        """
        return self.x_index_to_y_index_cooc


    def set_xy_cooc(self, xy_cooc):
        """
        Set the term to document co-occurrence map structure. This is a
        dictionary from a tuple (x_index (x), y_index (y)) to the
        occurrences, or frequency, of that pair (xy_cooc). For example
        x_index_to_y_index_cooc[(0, 3)] = 4 means that x_index
        '0' occurs '4' times in y_index 3.

        This is a sparse structure so 0's are not recorded.
        To check for presence of a term, document pair entry, use:
        'if (x_index, y_index) in self.x_index_to_y_index_cooc'.

        Parameters
        ----------
        xy_cooc : dict of (int, int) to int
            dictionary from a tuple (x_index (x), y_index (y)) to the occurrences, or frequency, of that pair.
        """
        self.x_index_to_y_index_cooc = xy_cooc


    def get_ax_map(self):
        """
        Get the x_cluster_index to term indices map. This tells us which
        term clusters (a's) contain which terms (x's). This is a zero based
        system. For example, an entry in this file looks like this: '3'. Lets
        say this is on line 7 of the file, since it is a zero based counting
        system, this tells us the x_index '6' belongs to term cluster '3'.
        This structure is built in the read_xa_map() method in Section A

        Returns
        -------
        A dictionary that maps from term cluster indices to a list of term indices indicating membership in that
        term cluster
        """
        return self.x_cluster_to_x_map


    def set_ax_map(self, ax_map):
        """
        Set the x_cluster_index to term indices map. This tells us which
        term clusters (a's) contain which terms (x's). This is a zero based
        system. For example, an entry in this file looks like this: '3'. Lets
        say this is on line 7 of the file, since it is a zero based counting
        system, this tells us the x_index '6' belongs to term cluster '3'

        Parameters
        ----------
        ax_map : dict of int to int
            dictionary to a list of terms for each of the term clusters (ax_map)
        """
        self.x_cluster_to_x_map = ax_map


    def get_yx_map(self):
        """
        Get the y_index to term indices map structure. This structure
        is built in the read_xy_cooc() method in Section A.

        Returns
        -------
        A dictionary of y_indices to a list of x_indices
        This allows us to query which terms (x's) occur in a document (y)
        """
        return self.yx_map


    def set_yx_map(self, yx_map):
        """
        Set the y_index to term indices map structure.

        Parameters
        ----------
        yx_map : dict of int to int
            dictionary of y_indices to a list of x_indices (yx_map)
        """
        self.yx_map = yx_map


    def get_yb_map(self):
        """
        Get the y_index to y_cluster_index map structure. This
        tells us which documents (y's) belong to which document clusters
        (b's). This is a zero based system. For example, an entry in this file
        looks like this: '3'. Lets say this is on line 7 of the file,
        since it is a zero based counting system, this tells us the
        x_index '6' belongs to term cluster '3'. This structure is built
        in the read_yb_map() method in Section A.

        Returns
        -------
        A dictionary that maps from the y_index to the cluster_index (yb_map)
        """
        return self.y_to_y_cluster_map


    def set_yb_map(self, yb_map):
        """
        Set the y_index to y_cluster_index map structure. This
        tells us which documents (y's) belong to which document clusters
        (b's). This is a zero based system. For example, an entry in this file
        looks like this: '3'. Lets say this is on line 7 of the file,
        since it is a zero based counting system, this tells us the
        x_index '6' belongs to term cluster '3'.

        Parameters
        ----------
        yb_map : dict of int to int
            dictionary that maps from the y_index to the cluster_index (yb_map)
        """
        self.y_to_y_cluster_map = yb_map


    def get_by_map(self):
        """
        Get the y_cluster_index to y_index map structure.
        This is the opposite of the ym_map.
        This structure is built in the read_yb_map() method in Section A.

        Returns
        -------
        A dictionary that maps from a y_cluster_index to a list of document indices.
        """
        return self.y_cluster_map


    def set_by_map(self, by_map):
        """
        Set the y_cluster_index to y_index map structure. This is the opposite of the ym_map.

        Parameters
        ----------
        by_map : dict of int to list of int
            dictionary to a list of documents for each of the document clusters (by_map)
        """
        self.y_cluster_map = by_map


    def get_ba_cooc(self):
        """
        Get the y_cluster_index to a list of tuples of
        x_cluster_index and co-occurrences structure.  The source file
        contains the sparse matrix data representing the occurrences,
        or frequency, between x_clusters (a's) and y_clusters
        (b's). An example entry in this file is 0\t3\t88. This translates to
        the terms in x_cluster_index '0' occur in the documents in
        y_cluster_index '3' a total of 88 times. This structure is
        built in the read_ab_cooc() method in Section A

        Returns
        -------
        A dictionary that maps from a y_cluster_index to a list
        of tuples of term cluster indices and frequency
        """
        return self.y_cluster_to_x_cluster


    def set_ba_cooc(self, ba_cooc):
        """
        Set the y_cluster_index to a list of tuples of
        x_cluster_index and co-occurrences structure.  The source file
        contains the sparse matrix data representing the occurrences,
        or frequency, between x_clusters (a's) and y_clusters
        (b's). An example entry in this file is 0\t3\t88. This translates to
        the terms in x_cluster_index '0' occur in the documents in
        y_cluster_index '3' a total of 88 times.

        Parameters
        ----------
        ba_cooc : dict of (int, int) to int
            dictionary to an list of tuples of term cluster indices, to frequency. This corresponds to a ba_cooc
            matrix as we are keying on the document clusters, the columns of the matrix.
        """
        self.y_cluster_to_x_cluster = ba_cooc


    def get_xb_cooc(self):
        """
        Get the x_index to y_cluster_index co-occurrences
        structure. This contains the sparse matrix data representing the
        occurrences, or frequency, between terms (x's) and document clusters
        (b's). An example entry in the source file is 0\t3\t88. This
        translates to x_index '0' occurs in y_cluster '3' a total
        of 88 times. This structure is built in the read_xb_cooc() method in
        Section A.

        Returns
        -------
        A dictionary that maps from a tuple of (x_index, y_cluster_index)
        to their co-occurrence frequency.
        """
        return self.x_index_and_y_cluster_index_to_frequency


    def set_xb_cooc(self, xb_cooc):
        """
        Set the x_index to y_cluster_index co-occurrences
        structure. This contains the sparse matrix data representing the
        occurrences, or frequency, between terms (x's) and document clusters
        (b's). An example entry in the source file is 0\t3\t88. This
        translates to x_index '0' occurs in y_cluster '3' a total
        of 88 times.

        Parameters
        ----------
        xb_cooc : dict of (int, int) to int
            dictionary of tuples of x_indices and y_cluster_indices, to frequency. (xb_map)
        """
        self.x_index_and_y_cluster_index_to_frequency = xb_cooc


    def get_bx_cooc(self):
        """
        Get the y_cluster_index to the x_indices co-occurrences
        structure. This contains the sparse matrix data representing the
        occurrences, or frequency, between terms (x's) and document clusters
        (b's). An example entry in the source file is 0\t3\t88. This
        translates to x_index '0' occurs in y_cluster '3' a total
        of 88 times. This structure is built in the read_xb_cooc() method in
        Section A.

        Returns
        -------
        A dictionary that maps from a y_cluster_index to a list
        of tuples of x_indices and their frequency.
        """
        return self.y_cluster_and_x_indices_to_frequency


    def set_bx_cooc(self, bx_cooc):
        """
        Set the y_cluster_index to the x_indices co-occurrences
        structure. This contains the sparse matrix data representing the
        occurrences, or frequency, between terms (x's) and document clusters
        (b's). An example entry in the source file is 0\t3\t88. This
        translates to x_index '0' occurs in y_cluster '3' a total
        of 88 times.

        Parameters
        ----------
        bx_cooc : dict of (int, int) to int
            dictionary to a list of tuples of x_indices, to frequency. (bx_map)
        """
        self.y_cluster_and_x_indices_to_frequency = bx_cooc


    def get_xy_pmi(self):
        """
        Get the x_index to y_index Pointwise Mutual Informaion
        measure structure. Note: some of the PMI values are negative -
        Positive PMI means that that the term is MORE likely to occur in this
        document than it is overall, negative should mean it's LESS likely to
        occur this document than it is overall, and zero means that it's AS
        likely to occur in this document as any other. This structure is
        built in the read_xy_assoc() method in Section A

        Returns
        -------
        A dictionary from x_indices to a list of tuples of y_indices
        and their relative PMI
        """
        return self.x_to_y_pmi


    def set_xy_pmi(self, xy_pmi):
        """
        Set the x_index to y_index Pointwise Mutual Informaion
        measure structure. Note: some of the PMI values are negative -
        Positive PMI means that that the term is MORE likely to occur in this
        document than it is overall, negative should mean it's LESS likely to
        occur this document than it is overall, and zero means that it's AS
        likely to occur in this document as any other.

        Parameters
        ----------
        xy_pmi : dict from int to (int, float)
            dictionary from x_indices to a list of tuples of y_indices and their relative PMI
        """
        self.x_to_y_pmi = xy_pmi


    def get_xb_pmi(self):
        """
        Get the x_index to y_cluster_index Pointwise Mutual
        Informaion measure structure. Note: some of the PMI values are
        negative - Positive PMI means that that the term is MORE likely to
        occur in this document cluster than it is overall, negative should
        mean it's LESS likely to occur this doc cluster than it is overall,
        and zero means that it's AS likely to occur in this doc cluster as
        any other. This structure is built in the read_xb_assoc() method in
        Section A

        Returns
        -------
        A dictionary from x_indices to a list of tuples of y_cluster_indices and their relative PMI
        """
        return self.x_to_y_cluster_pmi


    def set_xb_pmi(self, xb_pmi):
        """
        Set the x_index to y_cluster_index Pointwise Mutual
        Informaion measure structure. Note: some of the PMI values are
        negative - Positive PMI means that that the term is MORE likely to
        occur in this document cluster than it is overall, negative should
        mean it's LESS likely to occur this doc cluster than it is overall,
        and zero means that it's AS likely to occur in this doc cluster as
        any other.

        Parameters
        ----------
        xb_pmi : dict from int to (int, float)
            dictionary from x_indices to a list of tuples of y_cluster_indices and their relative PMI
        """
        self.x_to_y_cluster_pmi = xb_pmi


    def get_xx_divergence(self):
        """
        Get the x_index pair, as a tuple, to their measured divergence (or
        distance). An example entry from the source file is 0\t3\t0.224. This
        translates to x_index '0' and x_index '3' have a divergence
        measure of 0.224. Divergence is like distance, the smaller the
        number, the closer those two terms should be considered in meaning or
        context. This structure is built in the read_xx_assoc() method in
        Section A

        Returns
        -------
        A dictionary from a pair, as a tuple, of term indices to their relative
        divergence, or distance, from each other
        """
        return self.x_to_x_divergence


    def set_xx_divergence(self, xx_divergence):
        """
        Set the x_index pair, as a tuple, to their measured divergence (or
        distance). An example entry from the source file is 0\t3\t0.224. This
        translates to x_index '0' and x_index '3' have a divergence
        measure of 0.224. Divergence is like distance, the smaller the
        number, the closer those two terms should be considered in meaning or
        context.

        Parameters
        ----------
        xx_divergence :  dict from int to (int, float)
            dictionary from a tuple of term indices to their relative divergence, or distance, from each other
        """
        self.x_to_x_divergence = xx_divergence


    def get_x_margins(self):
        """
        Get the term totals map. This is a dictionary that maps from the term index (x) to the total number of
        occurrences for that term in the corpus.

        Returns
        -------
        dictionary that maps from the term index (x) to the total number
        of occurrences for that term in the corpus.
        """
        return self.x_totals_map


    def set_x_margins(self, x_margins):
        """
        Set the term totals map. This is a dictionary that maps from
        the term index (x) to the total number of
        occurrences for that term in the corpus.

        Parameters
        ----------
        x_margins : dict from int to int
            dictionary that maps from term index to the total occurrences for that term in the corps
        """
        self.x_totals_map = x_margins


    def get_b_margins(self):
        """
        Get the document cluster totals map. This is a dictionary that maps from
        the document clusters (b) to the
        total number of term occurrences for that document cluster.

        Returns
        -------
        dictionary that maps from the document cluster index (b)
        to the total number of term occurrences for that
        document cluster.
        """
        return self.y_cluster_totals_map


    def set_b_margins(self, b_margins):
        """
        Set the document cluster totals map. This is a dictionary that maps from
        the document clusters (b) to the
        total number of term occurrences for that document cluster.

        Parameters
        ----------
        b_margins : dict from int to int
            dictionary that maps from document cluster to the total term occurrences for that document cluster
        """
        self.y_cluster_totals_map = b_margins


# TODO Developer only,
# but I'll leave it here for now, if only for the docstring.
if __name__ == "__main__":

    def main(input_directory, #: "location of the by document co-clustering data",
             adj_input_directory: ("location of the by adjacency co-clustering data", 'option'),
             target_label: ("portion of the file name that indicates this is a target document", 'option'),
             non_target_label: ("portion of the file name that indicates this is a non target document", 'option')):
        """
        Main entry point to the co-clustering class

        Parameters
        ----------
        input_directory : string
            location of the by-document co_clustering data
        adj_input_directory : string
            location of the by-adj co_clustering data
        target_label : string
            string to look for in the document name that indicates this is
            a target document. This information is generally not known,
            but if it is this will allow the client to look at the purity
            of document clusters and what terms are most associated with
            target documents etc.
        non_target_label : string
            string to look for in the document name that indicates this is
            a non-target document. This information is generally not known,
            but if it is this will allow the client to look at the purity
            of document clusters  and what terms are most associated with
            non-target documents etc.
        """
        Coclustering(input_directory,
                     adj_input_directory=adj_input_directory,
                     target_label=target_label,
                     non_target_label=non_target_label)

    plac.call(main)
